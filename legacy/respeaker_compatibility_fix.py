#!/usr/bin/env python3
"""
ReSpeaker 2-Micsä¸“ç”¨å…¼å®¹æ€§ä¿®å¤
ä½¿ç”¨åº•å±‚éŸ³é¢‘å¤„ç†å’Œå¤‡ç”¨æ£€æµ‹ç­–ç•¥
"""

import os
import sys
import time
import signal
import threading
import numpy as np
import struct

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

# åŠ è½½ç¯å¢ƒå˜é‡
env_file = ".ai_pet_env"
if os.path.exists(env_file):
    with open(env_file, 'r') as f:
        for line in f:
            line = line.strip()
            if line and not line.startswith('#') and '=' in line:
                if line.startswith('export '):
                    line = line[7:]
                key, value = line.split('=', 1)
                value = value.strip('"\'')
                os.environ[key] = value

try:
    import sounddevice as sd
    import pvporcupine
    from scipy import signal as scipy_signal
    print("âœ… æ‰€æœ‰æ¨¡å—å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âŒ æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    sys.exit(1)

# å…¨å±€å˜é‡
detector_running = False
wake_word_count = 0

def create_multiple_porcupines():
    """åˆ›å»ºå¤šä¸ªä¸åŒçµæ•åº¦çš„Porcupineå®ä¾‹"""
    access_key = os.getenv('PICOVOICE_ACCESS_KEY')
    wake_word_file = 'wake_words/kk_zh_raspberry-pi_v3_0_0.ppn'
    model_file = 'models/porcupine/porcupine_params_zh.pv'
    
    porcupines = []
    sensitivities = [0.1, 0.3, 0.5, 0.7, 0.9]
    
    for sensitivity in sensitivities:
        try:
            porcupine = pvporcupine.create(
                access_key=access_key,
                keyword_paths=[wake_word_file],
                model_path=model_file,
                sensitivities=[sensitivity]
            )
            porcupines.append((porcupine, sensitivity))
            print(f"âœ… Porcupineåˆå§‹åŒ–æˆåŠŸ (çµæ•åº¦: {sensitivity})")
        except Exception as e:
            print(f"âŒ Porcupineåˆå§‹åŒ–å¤±è´¥ (çµæ•åº¦: {sensitivity}): {e}")
    
    return porcupines

def advanced_audio_preprocessing(audio_data):
    """é«˜çº§éŸ³é¢‘é¢„å¤„ç†ä¸“é—¨é’ˆå¯¹ReSpeaker"""
    
    # è½¬æ¢ä¸ºfloatè¿›è¡Œå¤„ç†
    audio_float = audio_data.astype(np.float32)
    
    # 1. å¼ºåŠ›DCåç§»ç§»é™¤ï¼ˆæ»‘åŠ¨å¹³å‡ï¼‰
    window_size = min(256, len(audio_float) // 4)
    if window_size > 10:
        dc_trend = np.convolve(audio_float, np.ones(window_size)/window_size, mode='same')
        audio_float = audio_float - dc_trend
    else:
        audio_float = audio_float - np.mean(audio_float)
    
    # 2. å¤šçº§æ»¤æ³¢
    # é«˜é€šæ»¤æ³¢å™¨ - ç§»é™¤60Hzä»¥ä¸‹
    try:
        nyquist = 16000 / 2
        high_cutoff = 60 / nyquist
        b_high, a_high = scipy_signal.butter(3, high_cutoff, btype='high')
        audio_float = scipy_signal.filtfilt(b_high, a_high, audio_float)
        
        # ä½é€šæ»¤æ³¢å™¨ - ç§»é™¤8000Hzä»¥ä¸Š
        low_cutoff = 8000 / nyquist
        b_low, a_low = scipy_signal.butter(3, low_cutoff, btype='low')
        audio_float = scipy_signal.filtfilt(b_low, a_low, audio_float)
    except:
        pass
    
    # 3. åŠ¨æ€èŒƒå›´å‹ç¼©
    # è®¡ç®—RMS
    rms = np.sqrt(np.mean(audio_float ** 2))
    if rms > 0:
        # è½¯å‹ç¼©
        target_rms = 5000
        if rms > target_rms:
            compression_ratio = 0.6
            excess = audio_float / rms * target_rms
            compressed = np.sign(audio_float) * (np.abs(excess) ** compression_ratio) * target_rms
            audio_float = compressed
        else:
            # è½»å¾®æ”¾å¤§å°ä¿¡å·
            audio_float = audio_float * (target_rms / rms) * 0.8
    
    # 4. å»å™ªï¼ˆç®€å•ï¼‰
    # æ£€æµ‹å¹¶å‡å°‘é™éŸ³æ®µçš„å™ªéŸ³
    energy_threshold = np.percentile(np.abs(audio_float), 70)
    quiet_mask = np.abs(audio_float) < energy_threshold
    if np.sum(quiet_mask) > len(audio_float) * 0.3:  # å¦‚æœè¶…è¿‡30%æ˜¯å®‰é™çš„
        noise_estimate = np.mean(np.abs(audio_float[quiet_mask]))
        audio_float[quiet_mask] *= 0.3  # å‡å°‘å®‰é™æ®µçš„å™ªéŸ³
    
    # 5. é™å¹…å’Œæ•´å½¢
    audio_float = np.clip(audio_float, -32000, 32000)
    
    # 6. æ·»åŠ è½»å¾®çš„é¢„åŠ é‡ï¼ˆå¢å¼ºé«˜é¢‘ï¼‰
    try:
        pre_emphasis = 0.97
        audio_float = np.append(audio_float[0], audio_float[1:] - pre_emphasis * audio_float[:-1])
    except:
        pass
    
    return audio_float.astype(np.int16)

def respeaker_detection_worker(porcupines, device_id):
    """ReSpeakerä¸“ç”¨æ£€æµ‹å·¥ä½œçº¿ç¨‹"""
    global detector_running, wake_word_count
    
    frame_length = 512  # Porcupineå¸§é•¿åº¦
    device_sample_rate = 48000
    target_sample_rate = 16000
    device_frame_length = int(frame_length * device_sample_rate / target_sample_rate)
    
    print(f"ğŸ¤ ReSpeakerä¸“ç”¨æ£€æµ‹çº¿ç¨‹å¯åŠ¨")
    print(f"ğŸ“Š è®¾å¤‡: 48kHz, ç›®æ ‡: 16kHz, å¸§é•¿åº¦: {frame_length}")
    print(f"ğŸ”§ ä½¿ç”¨ {len(porcupines)} ä¸ªä¸åŒçµæ•åº¦çš„æ£€æµ‹å™¨")
    print("ğŸ§ª å¯ç”¨é«˜çº§éŸ³é¢‘é¢„å¤„ç†")
    
    frame_count = 0
    detection_votes = []  # æŠ•ç¥¨æœºåˆ¶
    
    try:
        while detector_running:
            # å½•åˆ¶éŸ³é¢‘
            audio_chunk = sd.rec(
                device_frame_length,
                samplerate=device_sample_rate,
                channels=1,
                device=device_id,
                dtype=np.int16
            )
            sd.wait()
            
            # é‡é‡‡æ ·
            audio_data = audio_chunk.flatten()
            resampled_audio = scipy_signal.resample(audio_data, frame_length).astype(np.int16)
            
            # é«˜çº§é¢„å¤„ç†
            processed_audio = advanced_audio_preprocessing(resampled_audio)
            
            # ä½¿ç”¨å¤šä¸ªæ£€æµ‹å™¨è¿›è¡ŒæŠ•ç¥¨
            detection_results = []
            for porcupine, sensitivity in porcupines:
                try:
                    keyword_index = porcupine.process(processed_audio)
                    if keyword_index >= 0:
                        detection_results.append(sensitivity)
                except Exception as e:
                    print(f"âš ï¸ æ£€æµ‹é”™è¯¯ (çµæ•åº¦{sensitivity}): {e}")
                    continue
            
            frame_count += 1
            
            # æŠ•ç¥¨æœºåˆ¶ï¼šå¦‚æœæœ‰æ£€æµ‹ç»“æœï¼Œè®°å½•
            if detection_results:
                detection_votes.extend(detection_results)
                
                # å¦‚æœåœ¨æœ€è¿‘10å¸§å†…æœ‰å¤šæ¬¡æ£€æµ‹ï¼Œè®¤ä¸ºæ˜¯æœ‰æ•ˆå”¤é†’
                recent_votes = [v for v in detection_votes if True]  # ä¿ç•™æ‰€æœ‰æŠ•ç¥¨
                
                if len(recent_votes) >= 2:  # è‡³å°‘2ç¥¨
                    wake_word_count += 1
                    avg_sensitivity = np.mean(recent_votes)
                    print(f"\nğŸ‰ æ£€æµ‹åˆ°å”¤é†’è¯ 'å¿«å¿«'ï¼(ç¬¬{wake_word_count}æ¬¡)")
                    print(f"   ğŸ“Š æŠ•ç¥¨ç»“æœ: {len(recent_votes)}ç¥¨, å¹³å‡çµæ•åº¦: {avg_sensitivity:.2f}")
                    print("âœ¨ è¯·ç»§ç»­è¯´è¯æµ‹è¯•æ›´å¤šæ£€æµ‹...")
                    
                    # æ¸…ç©ºæŠ•ç¥¨ï¼Œé¿å…é‡å¤è®¡æ•°
                    detection_votes = []
            
            # æ¸…ç†æ—§æŠ•ç¥¨ï¼ˆä¿æŒçª—å£å¤§å°ï¼‰
            if len(detection_votes) > 20:
                detection_votes = detection_votes[-10:]
            
            # å®šæœŸçŠ¶æ€è¾“å‡º
            if frame_count % (target_sample_rate // frame_length * 5) == 0:
                rms_original = np.sqrt(np.mean(resampled_audio.astype(np.float32) ** 2))
                rms_processed = np.sqrt(np.mean(processed_audio.astype(np.float32) ** 2))
                votes_recent = len([v for v in detection_votes])
                print(f"ğŸ”„ å¸§{frame_count}: åŸå§‹RMS={rms_original:.0f}, å¤„ç†åRMS={rms_processed:.0f}, è¿‘æœŸæŠ•ç¥¨={votes_recent}, æ£€æµ‹åˆ°{wake_word_count}æ¬¡")
                
    except Exception as e:
        print(f"âŒ æ£€æµ‹çº¿ç¨‹é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
    
    print(f"ğŸ›‘ æ£€æµ‹ç»“æŸ: å…±å¤„ç† {frame_count} å¸§ï¼Œæ£€æµ‹åˆ° {wake_word_count} æ¬¡å”¤é†’è¯")

def signal_handler(sig, frame):
    global detector_running
    print('\nğŸ›‘ åœæ­¢æ£€æµ‹...')
    detector_running = False
    time.sleep(1)
    print(f"ğŸ“Š æœ€ç»ˆç»Ÿè®¡: æ£€æµ‹åˆ° {wake_word_count} æ¬¡å”¤é†’è¯")
    sys.exit(0)

# ä¸»ç¨‹åº
signal.signal(signal.SIGINT, signal_handler)

print("ğŸ”§ ReSpeaker 2-Mics ä¸“ç”¨å…¼å®¹æ€§ä¿®å¤")
print("=" * 60)
print("ğŸ¯ ä¸“é—¨è§£å†³ReSpeakerä¸Porcupineçš„å…¼å®¹æ€§é—®é¢˜")
print("ğŸ”¬ ä½¿ç”¨å¤šæ£€æµ‹å™¨æŠ•ç¥¨æœºåˆ¶å’Œé«˜çº§éŸ³é¢‘é¢„å¤„ç†")

# æŸ¥æ‰¾ReSpeakerè®¾å¤‡
devices = sd.query_devices()
respeaker_device = None

for i, device in enumerate(devices):
    if device['max_input_channels'] > 0:
        name = device['name'].lower()
        if 'seeed' in name or 'array' in name:
            respeaker_device = i
            print(f"âœ… æ‰¾åˆ°ReSpeakerè®¾å¤‡: {device['name']} (ID: {i})")
            break

if respeaker_device is None:
    print("âŒ æœªæ‰¾åˆ°ReSpeakerè®¾å¤‡")
    sys.exit(1)

# åˆ›å»ºå¤šä¸ªPorcupineå®ä¾‹
porcupines = create_multiple_porcupines()
if not porcupines:
    print("âŒ æ— æ³•åˆ›å»ºPorcupineå®ä¾‹")
    sys.exit(1)

# æµ‹è¯•éŸ³é¢‘å½•åˆ¶
try:
    print("ğŸ§ª æµ‹è¯•ReSpeakeréŸ³é¢‘å½•åˆ¶...")
    test_audio = sd.rec(1024, samplerate=48000, channels=1, device=respeaker_device, dtype=np.int16)
    sd.wait()
    
    # æµ‹è¯•é¢„å¤„ç†
    processed_test = advanced_audio_preprocessing(test_audio.flatten())
    original_stats = f"å¹³å‡å€¼={np.mean(test_audio):.0f}, RMS={np.sqrt(np.mean(test_audio.astype(np.float32)**2)):.0f}"
    processed_stats = f"å¹³å‡å€¼={np.mean(processed_test):.0f}, RMS={np.sqrt(np.mean(processed_test.astype(np.float32)**2)):.0f}"
    
    print(f"âœ… éŸ³é¢‘å½•åˆ¶å’Œé¢„å¤„ç†æµ‹è¯•æˆåŠŸ")
    print(f"   åŸå§‹éŸ³é¢‘: {original_stats}")
    print(f"   å¤„ç†å: {processed_stats}")
    
except Exception as e:
    print(f"âŒ éŸ³é¢‘å½•åˆ¶æµ‹è¯•å¤±è´¥: {e}")
    sys.exit(1)

# å¼€å§‹æ£€æµ‹
detector_running = True
detection_thread = threading.Thread(target=respeaker_detection_worker, args=(porcupines, respeaker_device), daemon=True)
detection_thread.start()

print("âœ… ReSpeakerä¸“ç”¨å”¤é†’è¯æ£€æµ‹å·²å¯åŠ¨")
print("ğŸ—£ï¸ è¯·æ¸…æ™°åœ°è¯´ 'å¿«å¿«' æ¥æµ‹è¯•...")
print("â±ï¸ å°†è¿è¡Œ60ç§’ï¼ŒæŒ‰Ctrl+Cå¯éšæ—¶åœæ­¢")
print("ğŸ’¡ æ–°ç‰¹æ€§:")
print("   - å¤šçµæ•åº¦æŠ•ç¥¨æœºåˆ¶")
print("   - é«˜çº§éŸ³é¢‘é¢„å¤„ç†")
print("   - åŠ¨æ€èŒƒå›´å‹ç¼©")
print("   - å¤šçº§æ»¤æ³¢å»å™ª")

try:
    # è¿è¡Œ60ç§’
    for i in range(60):
        time.sleep(1)
        if not detector_running:
            break
            
    detector_running = False
    print(f"\nâ° æµ‹è¯•å®Œæˆ!")
    print(f"ğŸ“Š ç»“æœ: å…±æ£€æµ‹åˆ° {wake_word_count} æ¬¡å”¤é†’è¯ 'å¿«å¿«'")
    
    if wake_word_count > 0:
        print("ğŸ‰ æˆåŠŸï¼ReSpeakerå…¼å®¹æ€§é—®é¢˜å·²è§£å†³ï¼")
        print("ğŸ’¡ å…³é”®æ”¹è¿›:")
        print("   - å¤šæ£€æµ‹å™¨æŠ•ç¥¨æé«˜äº†å¯é æ€§")
        print("   - é«˜çº§é¢„å¤„ç†æ”¹å–„äº†éŸ³é¢‘è´¨é‡")
        print("   - ç°åœ¨å¯ä»¥æ­£å¸¸ä½¿ç”¨ReSpeakerè¿›è¡Œå”¤é†’è¯æ£€æµ‹")
    else:
        print("âš ï¸ ä»æœªæ£€æµ‹åˆ°å”¤é†’è¯")
        print("ğŸ” å¯èƒ½çš„åŸå› :")
        print("   - å”¤é†’è¯æ–‡ä»¶å¯èƒ½æœ‰é—®é¢˜")
        print("   - éœ€è¦æ£€æŸ¥ä¸­æ–‡å‘éŸ³æ˜¯å¦æ ‡å‡†")
        print("   - ReSpeakerç¡¬ä»¶å¯èƒ½å­˜åœ¨æ›´æ·±å±‚é—®é¢˜")

except KeyboardInterrupt:
    pass

finally:
    detector_running = False
    # æ¸…ç†Porcupineå®ä¾‹
    for porcupine, _ in porcupines:
        try:
            porcupine.delete()
        except:
            pass
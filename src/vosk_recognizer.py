#!/usr/bin/python3
"""
Voskè¯­éŸ³è¯†åˆ«æ¨¡å— - æ”¯æŒä¸­æ–‡ç¦»çº¿è¯­éŸ³è¯†åˆ«
"""

import json
import logging
import os
import wave
import pyaudio
from typing import Optional, Dict, Any
import threading
import time
import numpy as np
from scipy import signal

logger = logging.getLogger(__name__)

class VoskRecognizer:
    """Voskè¯­éŸ³è¯†åˆ«å™¨"""
    
    def __init__(self, model_path: str = None, sample_rate: int = 16000):
        """
        åˆå§‹åŒ–Voskè¯†åˆ«å™¨
        Args:
            model_path: Voskæ¨¡å‹è·¯å¾„
            sample_rate: é‡‡æ ·ç‡
        """
        self.sample_rate = sample_rate
        self.model = None
        self.recognizer = None
        self.is_available = False
        
        # å°è¯•å¯¼å…¥Vosk
        try:
            import vosk
            self.vosk = vosk
            logger.info("Voskåº“å¯¼å…¥æˆåŠŸ")
        except ImportError:
            logger.warning("Voskåº“æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install vosk")
            return
        
        # è®¾ç½®æ¨¡å‹è·¯å¾„
        if model_path is None:
            model_path = self._find_chinese_model()
        
        if model_path and os.path.exists(model_path):
            self._initialize_model(model_path)
        else:
            logger.warning("æœªæ‰¾åˆ°Voskä¸­æ–‡æ¨¡å‹ï¼Œè¯·ä¸‹è½½æ¨¡å‹æ–‡ä»¶")
            self._show_model_download_instructions()
    
    def _find_chinese_model(self) -> Optional[str]:
        """æŸ¥æ‰¾ä¸­æ–‡æ¨¡å‹"""
        possible_paths = [
            "models/vosk-model-small-cn-0.22",
            "models/vosk-model-cn-0.22", 
            "../models/vosk-model-small-cn-0.22",
            "../models/vosk-model-cn-0.22",
            "/opt/vosk-models/vosk-model-small-cn-0.22",
            "/opt/vosk-models/vosk-model-cn-0.22",
            os.path.expanduser("~/vosk-models/vosk-model-small-cn-0.22"),
            os.path.expanduser("~/vosk-models/vosk-model-cn-0.22")
        ]
        
        for path in possible_paths:
            if os.path.exists(path):
                logger.info(f"æ‰¾åˆ°Voskä¸­æ–‡æ¨¡å‹: {path}")
                return path
        
        return None
    
    def _initialize_model(self, model_path: str):
        """åˆå§‹åŒ–æ¨¡å‹"""
        try:
            # è®¾ç½®æ—¥å¿—çº§åˆ«ï¼ˆå‡å°‘Voskçš„è¾“å‡ºï¼‰
            self.vosk.SetLogLevel(-1)
            
            # åŠ è½½æ¨¡å‹
            self.model = self.vosk.Model(model_path)
            self.recognizer = self.vosk.KaldiRecognizer(self.model, self.sample_rate)
            
            # è®¾ç½®è¯†åˆ«å™¨é…ç½®
            self.recognizer.SetWords(True)
            self.recognizer.SetPartialWords(True)
            
            self.is_available = True
            logger.info(f"Voskæ¨¡å‹åˆå§‹åŒ–æˆåŠŸ: {model_path}")
            
        except Exception as e:
            logger.error(f"Voskæ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
            self.is_available = False
    
    def _show_model_download_instructions(self):
        """æ˜¾ç¤ºæ¨¡å‹ä¸‹è½½è¯´æ˜"""
        logger.info("=" * 50)
        logger.info("Voskä¸­æ–‡æ¨¡å‹ä¸‹è½½è¯´æ˜:")
        logger.info("1. åˆ›å»ºæ¨¡å‹ç›®å½•: mkdir -p models")
        logger.info("2. ä¸‹è½½å°å‹ä¸­æ–‡æ¨¡å‹ (çº¦40MB):")
        logger.info("   wget https://alphacephei.com/vosk/models/vosk-model-small-cn-0.22.zip")
        logger.info("3. è§£å‹æ¨¡å‹:")
        logger.info("   unzip vosk-model-small-cn-0.22.zip -d models/")
        logger.info("4. æˆ–è€…ä¸‹è½½å®Œæ•´ä¸­æ–‡æ¨¡å‹ (çº¦1.2GB):")
        logger.info("   wget https://alphacephei.com/vosk/models/vosk-model-cn-0.22.zip")
        logger.info("=" * 50)
    
    def recognize_from_audio_data(self, audio_data: bytes) -> Optional[str]:
        """
        ä»éŸ³é¢‘æ•°æ®è¯†åˆ«è¯­éŸ³
        Args:
            audio_data: éŸ³é¢‘æ•°æ® (16-bit PCM)
        Returns:
            è¯†åˆ«ç»“æœæ–‡æœ¬
        """
        if not self.is_available:
            return None
        
        try:
            # é‡ç½®è¯†åˆ«å™¨
            self.recognizer.Reset()
            
            # åˆ†å—å¤„ç†éŸ³é¢‘æ•°æ® (å…³é”®ä¿®å¤)
            chunk_size = 4096
            final_result = None
            
            for i in range(0, len(audio_data), chunk_size):
                chunk = audio_data[i:i+chunk_size]
                
                if self.recognizer.AcceptWaveform(chunk):
                    # æœ‰å®Œæ•´è¯†åˆ«ç»“æœ
                    result = json.loads(self.recognizer.Result())
                    text = result.get('text', '').strip()
                    if text:
                        logger.debug(f"Voskå—è¯†åˆ«ç»“æœ: {text}")
                        final_result = text
                        break
            
            # å…³é”®ä¿®å¤ï¼šå¤„ç†å®Œæ‰€æœ‰æ•°æ®åè·å–æœ€ç»ˆç»“æœ
            if not final_result:
                final_result_json = self.recognizer.FinalResult()
                final_result_dict = json.loads(final_result_json)
                final_result = final_result_dict.get('text', '').strip()
                logger.debug(f"Voskæœ€ç»ˆç»“æœ: {final_result}")
            
            if final_result:
                logger.info(f"âœ… Voskè¯†åˆ«æˆåŠŸ: {final_result}")
                return final_result
            else:
                logger.debug("ğŸ”‡ Voskæœªè¯†åˆ«åˆ°å†…å®¹")
                return None
            
        except Exception as e:
            logger.error(f"Voskè¯†åˆ«å¤±è´¥: {e}")
            return None
    
    def _resample_audio(self, audio_data: bytes, original_rate: int, target_rate: int) -> bytes:
        """
        é‡é‡‡æ ·éŸ³é¢‘æ•°æ®
        Args:
            audio_data: åŸå§‹éŸ³é¢‘æ•°æ®
            original_rate: åŸå§‹é‡‡æ ·ç‡
            target_rate: ç›®æ ‡é‡‡æ ·ç‡
        Returns:
            é‡é‡‡æ ·åçš„éŸ³é¢‘æ•°æ®
        """
        if original_rate == target_rate:
            return audio_data
        
        try:
            # è½¬æ¢ä¸ºnumpyæ•°ç»„
            audio_array = np.frombuffer(audio_data, dtype=np.int16)
            
            # è®¡ç®—é‡é‡‡æ ·åçš„æ ·æœ¬æ•°
            num_samples = int(len(audio_array) * target_rate / original_rate)
            
            # ä½¿ç”¨scipyè¿›è¡Œé‡é‡‡æ ·
            resampled_array = signal.resample(audio_array, num_samples)
            
            # è½¬æ¢å›int16å¹¶è¿”å›bytes
            return resampled_array.astype(np.int16).tobytes()
            
        except Exception as e:
            logger.error(f"éŸ³é¢‘é‡é‡‡æ ·å¤±è´¥: {e}")
            return audio_data

    def recognize_from_speech_recognition_audio(self, sr_audio) -> Optional[str]:
        """
        ä»SpeechRecognitionçš„AudioDataå¯¹è±¡è¯†åˆ«
        Args:
            sr_audio: speech_recognition.AudioDataå¯¹è±¡
        Returns:
            è¯†åˆ«ç»“æœæ–‡æœ¬
        """
        if not self.is_available:
            logger.debug("Voskä¸å¯ç”¨ï¼Œè·³è¿‡è¯†åˆ«")
            return None
        
        try:
            logger.debug("ğŸ¤ Voskå¼€å§‹å¤„ç†éŸ³é¢‘æ•°æ®...")
            
            # è·å–éŸ³é¢‘æ•°æ®
            audio_data = sr_audio.get_raw_data()
            logger.debug(f"éŸ³é¢‘æ•°æ®é•¿åº¦: {len(audio_data)} å­—èŠ‚")
            logger.debug(f"åŸå§‹é‡‡æ ·ç‡: {sr_audio.sample_rate} Hz")
            
            # å¤„ç†é‡‡æ ·ç‡ä¸åŒ¹é…çš„æƒ…å†µ
            if sr_audio.sample_rate != self.sample_rate:
                logger.info(f"ğŸ”„ é‡é‡‡æ ·: {sr_audio.sample_rate} Hz â†’ {self.sample_rate} Hz")
                audio_data = self._resample_audio(audio_data, sr_audio.sample_rate, self.sample_rate)
                logger.debug(f"é‡é‡‡æ ·åæ•°æ®é•¿åº¦: {len(audio_data)} å­—èŠ‚")
            
            result = self.recognize_from_audio_data(audio_data)
            if result:
                logger.debug(f"ğŸ¯ Voskè¯†åˆ«åŸå§‹ç»“æœ: '{result}'")
            else:
                logger.debug("ğŸ”‡ Voskæœªè¯†åˆ«åˆ°å†…å®¹")
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ Voskä»SpeechRecognitionéŸ³é¢‘è¯†åˆ«å¤±è´¥: {e}")
            return None
    
    def create_stream_recognizer(self):
        """åˆ›å»ºæµå¼è¯†åˆ«å™¨"""
        if not self.is_available:
            return None
        
        return VoskStreamRecognizer(self.model, self.sample_rate)

class VoskStreamRecognizer:
    """Voskæµå¼è¯†åˆ«å™¨ - ç”¨äºå®æ—¶è¯­éŸ³è¯†åˆ«"""
    
    def __init__(self, model, sample_rate: int = 16000):
        """
        åˆå§‹åŒ–æµå¼è¯†åˆ«å™¨
        Args:
            model: Voskæ¨¡å‹
            sample_rate: é‡‡æ ·ç‡
        """
        import vosk
        self.model = model
        self.sample_rate = sample_rate
        self.recognizer = vosk.KaldiRecognizer(model, sample_rate)
        self.recognizer.SetWords(True)
        
        self.is_listening = False
        self.audio_stream = None
        self.recognition_callback = None
        self.partial_callback = None
        
    def start_stream_recognition(self, 
                               recognition_callback=None, 
                               partial_callback=None):
        """
        å¼€å§‹æµå¼è¯†åˆ«
        Args:
            recognition_callback: å®Œæ•´è¯†åˆ«ç»“æœå›è°ƒ
            partial_callback: éƒ¨åˆ†è¯†åˆ«ç»“æœå›è°ƒ
        """
        self.recognition_callback = recognition_callback
        self.partial_callback = partial_callback
        self.is_listening = True
        
        try:
            # åˆå§‹åŒ–éŸ³é¢‘æµ
            pa = pyaudio.PyAudio()
            
            # æŸ¥æ‰¾ReSpeakerè®¾å¤‡ (ReSpeaker 2-Micsæ˜¾ç¤ºä¸º"array"è®¾å¤‡)
            respeaker_device_index = None
            for i in range(pa.get_device_count()):
                info = pa.get_device_info_by_index(i)
                device_name = info['name'].lower()
                # ReSpeaker 2-Micsé€šå¸¸æ˜¾ç¤ºä¸º"array"ï¼Œä¸”æœ‰2ä¸ªè¾“å…¥é€šé“
                if (('seeed' in device_name or 'respeaker' in device_name or 'array' in device_name) 
                    and info['maxInputChannels'] == 2):
                    respeaker_device_index = i
                    logger.info(f"æ‰¾åˆ°ReSpeakerè®¾å¤‡: {info['name']} (ç´¢å¼•: {i})")
                    break
            
            # ReSpeaker 2éœ€è¦ä½¿ç”¨48kHzé‡‡æ ·ç‡
            device_sample_rate = 48000 if respeaker_device_index is not None else self.sample_rate
            
            # ReSpeaker 2-Micséœ€è¦2å£°é“å½•éŸ³
            channels = 2 if respeaker_device_index is not None else 1
            
            self.audio_stream = pa.open(
                format=pyaudio.paInt16,
                channels=channels,
                rate=device_sample_rate,
                input=True,
                input_device_index=respeaker_device_index,  # ä½¿ç”¨ReSpeakerè®¾å¤‡
                frames_per_buffer=4096
            )
            
            # ä¿å­˜å£°é“æ•°
            self.channels = channels
            
            # ä¿å­˜å®é™…ä½¿ç”¨çš„é‡‡æ ·ç‡ï¼Œç”¨äºåç»­é‡é‡‡æ ·
            self.actual_sample_rate = device_sample_rate
            
            # å¯åŠ¨è¯†åˆ«çº¿ç¨‹
            recognition_thread = threading.Thread(
                target=self._stream_recognition_worker, 
                daemon=True
            )
            recognition_thread.start()
            
            logger.info("Voskæµå¼è¯†åˆ«å·²å¯åŠ¨")
            return True
            
        except Exception as e:
            logger.error(f"å¯åŠ¨æµå¼è¯†åˆ«å¤±è´¥: {e}")
            return False
    
    def stop_stream_recognition(self):
        """åœæ­¢æµå¼è¯†åˆ«"""
        self.is_listening = False
        
        if self.audio_stream:
            self.audio_stream.close()
            self.audio_stream = None
        
        logger.info("Voskæµå¼è¯†åˆ«å·²åœæ­¢")
    
    def _stream_recognition_worker(self):
        """æµå¼è¯†åˆ«å·¥ä½œçº¿ç¨‹"""
        logger.info("Voskæµå¼è¯†åˆ«çº¿ç¨‹å¯åŠ¨")
        
        while self.is_listening and self.audio_stream:
            try:
                # è¯»å–éŸ³é¢‘æ•°æ®
                data = self.audio_stream.read(4096, exception_on_overflow=False)
                
                # å¦‚æœæ˜¯ç«‹ä½“å£°ï¼Œè½¬æ¢ä¸ºå•å£°é“ï¼ˆå–å·¦å£°é“ï¼‰
                if hasattr(self, 'channels') and self.channels == 2:
                    # å°†ç«‹ä½“å£°è½¬æ¢ä¸ºå•å£°é“
                    audio_array = np.frombuffer(data, dtype=np.int16)
                    # é‡æ–°æ•´å½¢ä¸º (samples, channels)
                    stereo_array = audio_array.reshape(-1, 2)
                    # å–å·¦å£°é“
                    mono_array = stereo_array[:, 0]
                    data = mono_array.tobytes()
                
                # å¦‚æœéœ€è¦é‡é‡‡æ ·ï¼ˆReSpeakerä½¿ç”¨48kHzï¼ŒVoskéœ€è¦16kHzï¼‰
                if hasattr(self, 'actual_sample_rate') and self.actual_sample_rate != self.sample_rate:
                    data = self._resample_audio(data, self.actual_sample_rate, self.sample_rate)
                
                # å¤„ç†éŸ³é¢‘
                if self.recognizer.AcceptWaveform(data):
                    # å®Œæ•´è¯†åˆ«ç»“æœ
                    result = json.loads(self.recognizer.Result())
                    text = result.get('text', '').strip()
                    
                    if text and self.recognition_callback:
                        self.recognition_callback(text)
                else:
                    # éƒ¨åˆ†è¯†åˆ«ç»“æœ
                    partial_result = json.loads(self.recognizer.PartialResult())
                    partial_text = partial_result.get('partial', '').strip()
                    
                    if partial_text and self.partial_callback:
                        self.partial_callback(partial_text)
                
            except Exception as e:
                logger.error(f"æµå¼è¯†åˆ«é”™è¯¯: {e}")
                time.sleep(0.1)
        
        logger.info("Voskæµå¼è¯†åˆ«çº¿ç¨‹ç»“æŸ")

# æµ‹è¯•å‡½æ•°
def test_vosk_recognizer():
    """æµ‹è¯•Voskè¯†åˆ«å™¨"""
    print("=== Voskè¯­éŸ³è¯†åˆ«æµ‹è¯• ===")
    
    recognizer = VoskRecognizer()
    
    if not recognizer.is_available:
        print("âŒ Voskä¸å¯ç”¨")
        return False
    
    print("âœ… Voskåˆå§‹åŒ–æˆåŠŸ")
    
    # æµ‹è¯•æµå¼è¯†åˆ«
    stream_recognizer = recognizer.create_stream_recognizer()
    
    if stream_recognizer:
        print("âœ… æµå¼è¯†åˆ«å™¨åˆ›å»ºæˆåŠŸ")
        
        def on_recognition(text):
            print(f"ğŸ¤ è¯†åˆ«ç»“æœ: {text}")
        
        def on_partial(text):
            print(f"ğŸ”„ éƒ¨åˆ†ç»“æœ: {text}")
        
        try:
            if stream_recognizer.start_stream_recognition(on_recognition, on_partial):
                print("ğŸ™ï¸ å¼€å§‹è¯´è¯æµ‹è¯•ï¼ŒæŒ‰Ctrl+Cåœæ­¢...")
                
                # ä¿æŒè¿è¡Œ
                while True:
                    time.sleep(1)
            else:
                print("âŒ æµå¼è¯†åˆ«å¯åŠ¨å¤±è´¥")
                
        except KeyboardInterrupt:
            print("\næ­£åœ¨åœæ­¢...")
            stream_recognizer.stop_stream_recognition()
            print("æµ‹è¯•ç»“æŸ")
    
    return True

if __name__ == "__main__":
    test_vosk_recognizer()
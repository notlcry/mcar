#!/usr/bin/python3
"""
Voskè¯­éŸ³è¯†åˆ«æ¨¡å— - æ”¯æŒä¸­æ–‡ç¦»çº¿è¯­éŸ³è¯†åˆ«
"""

import json
import logging
import os
import wave
import pyaudio
from typing import Optional, Dict, Any
import threading
import time

logger = logging.getLogger(__name__)

class VoskRecognizer:
    """Voskè¯­éŸ³è¯†åˆ«å™¨"""
    
    def __init__(self, model_path: str = None, sample_rate: int = 16000):
        """
        åˆå§‹åŒ–Voskè¯†åˆ«å™¨
        Args:
            model_path: Voskæ¨¡å‹è·¯å¾„
            sample_rate: é‡‡æ ·ç‡
        """
        self.sample_rate = sample_rate
        self.model = None
        self.recognizer = None
        self.is_available = False
        
        # å°è¯•å¯¼å…¥Vosk
        try:
            import vosk
            self.vosk = vosk
            logger.info("Voskåº“å¯¼å…¥æˆåŠŸ")
        except ImportError:
            logger.warning("Voskåº“æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install vosk")
            return
        
        # è®¾ç½®æ¨¡å‹è·¯å¾„
        if model_path is None:
            model_path = self._find_chinese_model()
        
        if model_path and os.path.exists(model_path):
            self._initialize_model(model_path)
        else:
            logger.warning("æœªæ‰¾åˆ°Voskä¸­æ–‡æ¨¡å‹ï¼Œè¯·ä¸‹è½½æ¨¡å‹æ–‡ä»¶")
            self._show_model_download_instructions()
    
    def _find_chinese_model(self) -> Optional[str]:
        """æŸ¥æ‰¾ä¸­æ–‡æ¨¡å‹"""
        possible_paths = [
            "models/vosk-model-small-cn-0.22",
            "models/vosk-model-cn-0.22", 
            "../models/vosk-model-small-cn-0.22",
            "../models/vosk-model-cn-0.22",
            "/opt/vosk-models/vosk-model-small-cn-0.22",
            "/opt/vosk-models/vosk-model-cn-0.22",
            os.path.expanduser("~/vosk-models/vosk-model-small-cn-0.22"),
            os.path.expanduser("~/vosk-models/vosk-model-cn-0.22")
        ]
        
        for path in possible_paths:
            if os.path.exists(path):
                logger.info(f"æ‰¾åˆ°Voskä¸­æ–‡æ¨¡å‹: {path}")
                return path
        
        return None
    
    def _initialize_model(self, model_path: str):
        """åˆå§‹åŒ–æ¨¡å‹"""
        try:
            # è®¾ç½®æ—¥å¿—çº§åˆ«ï¼ˆå‡å°‘Voskçš„è¾“å‡ºï¼‰
            self.vosk.SetLogLevel(-1)
            
            # åŠ è½½æ¨¡å‹
            self.model = self.vosk.Model(model_path)
            self.recognizer = self.vosk.KaldiRecognizer(self.model, self.sample_rate)
            
            # è®¾ç½®è¯†åˆ«å™¨é…ç½®
            self.recognizer.SetWords(True)
            self.recognizer.SetPartialWords(True)
            
            self.is_available = True
            logger.info(f"Voskæ¨¡å‹åˆå§‹åŒ–æˆåŠŸ: {model_path}")
            
        except Exception as e:
            logger.error(f"Voskæ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
            self.is_available = False
    
    def _show_model_download_instructions(self):
        """æ˜¾ç¤ºæ¨¡å‹ä¸‹è½½è¯´æ˜"""
        logger.info("=" * 50)
        logger.info("Voskä¸­æ–‡æ¨¡å‹ä¸‹è½½è¯´æ˜:")
        logger.info("1. åˆ›å»ºæ¨¡å‹ç›®å½•: mkdir -p models")
        logger.info("2. ä¸‹è½½å°å‹ä¸­æ–‡æ¨¡å‹ (çº¦40MB):")
        logger.info("   wget https://alphacephei.com/vosk/models/vosk-model-small-cn-0.22.zip")
        logger.info("3. è§£å‹æ¨¡å‹:")
        logger.info("   unzip vosk-model-small-cn-0.22.zip -d models/")
        logger.info("4. æˆ–è€…ä¸‹è½½å®Œæ•´ä¸­æ–‡æ¨¡å‹ (çº¦1.2GB):")
        logger.info("   wget https://alphacephei.com/vosk/models/vosk-model-cn-0.22.zip")
        logger.info("=" * 50)
    
    def recognize_from_audio_data(self, audio_data: bytes) -> Optional[str]:
        """
        ä»éŸ³é¢‘æ•°æ®è¯†åˆ«è¯­éŸ³
        Args:
            audio_data: éŸ³é¢‘æ•°æ® (16-bit PCM)
        Returns:
            è¯†åˆ«ç»“æœæ–‡æœ¬
        """
        if not self.is_available:
            return None
        
        try:
            # é‡ç½®è¯†åˆ«å™¨
            self.recognizer.Reset()
            
            # å¤„ç†éŸ³é¢‘æ•°æ®
            if self.recognizer.AcceptWaveform(audio_data):
                result = json.loads(self.recognizer.Result())
                text = result.get('text', '').strip()
                if text:
                    logger.info(f"Voskè¯†åˆ«ç»“æœ: {text}")
                    return text
            
            # è·å–éƒ¨åˆ†ç»“æœ
            partial_result = json.loads(self.recognizer.PartialResult())
            partial_text = partial_result.get('partial', '').strip()
            if partial_text:
                logger.debug(f"Voskéƒ¨åˆ†è¯†åˆ«: {partial_text}")
                return partial_text
            
            return None
            
        except Exception as e:
            logger.error(f"Voskè¯†åˆ«å¤±è´¥: {e}")
            return None
    
    def recognize_from_speech_recognition_audio(self, sr_audio) -> Optional[str]:
        """
        ä»SpeechRecognitionçš„AudioDataå¯¹è±¡è¯†åˆ«
        Args:
            sr_audio: speech_recognition.AudioDataå¯¹è±¡
        Returns:
            è¯†åˆ«ç»“æœæ–‡æœ¬
        """
        if not self.is_available:
            logger.debug("Voskä¸å¯ç”¨ï¼Œè·³è¿‡è¯†åˆ«")
            return None
        
        try:
            logger.debug("ğŸ¤ Voskå¼€å§‹å¤„ç†éŸ³é¢‘æ•°æ®...")
            
            # è·å–éŸ³é¢‘æ•°æ®
            audio_data = sr_audio.get_raw_data()
            logger.debug(f"éŸ³é¢‘æ•°æ®é•¿åº¦: {len(audio_data)} å­—èŠ‚")
            
            # ç¡®ä¿é‡‡æ ·ç‡åŒ¹é…
            if sr_audio.sample_rate != self.sample_rate:
                logger.warning(f"é‡‡æ ·ç‡ä¸åŒ¹é…: {sr_audio.sample_rate} != {self.sample_rate}")
            
            result = self.recognize_from_audio_data(audio_data)
            if result:
                logger.debug(f"ğŸ¯ Voskè¯†åˆ«åŸå§‹ç»“æœ: '{result}'")
            else:
                logger.debug("ğŸ”‡ Voskæœªè¯†åˆ«åˆ°å†…å®¹")
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ Voskä»SpeechRecognitionéŸ³é¢‘è¯†åˆ«å¤±è´¥: {e}")
            return None
    
    def create_stream_recognizer(self):
        """åˆ›å»ºæµå¼è¯†åˆ«å™¨"""
        if not self.is_available:
            return None
        
        return VoskStreamRecognizer(self.model, self.sample_rate)

class VoskStreamRecognizer:
    """Voskæµå¼è¯†åˆ«å™¨ - ç”¨äºå®æ—¶è¯­éŸ³è¯†åˆ«"""
    
    def __init__(self, model, sample_rate: int = 16000):
        """
        åˆå§‹åŒ–æµå¼è¯†åˆ«å™¨
        Args:
            model: Voskæ¨¡å‹
            sample_rate: é‡‡æ ·ç‡
        """
        import vosk
        self.model = model
        self.sample_rate = sample_rate
        self.recognizer = vosk.KaldiRecognizer(model, sample_rate)
        self.recognizer.SetWords(True)
        
        self.is_listening = False
        self.audio_stream = None
        self.recognition_callback = None
        self.partial_callback = None
        
    def start_stream_recognition(self, 
                               recognition_callback=None, 
                               partial_callback=None):
        """
        å¼€å§‹æµå¼è¯†åˆ«
        Args:
            recognition_callback: å®Œæ•´è¯†åˆ«ç»“æœå›è°ƒ
            partial_callback: éƒ¨åˆ†è¯†åˆ«ç»“æœå›è°ƒ
        """
        self.recognition_callback = recognition_callback
        self.partial_callback = partial_callback
        self.is_listening = True
        
        try:
            # åˆå§‹åŒ–éŸ³é¢‘æµ
            pa = pyaudio.PyAudio()
            self.audio_stream = pa.open(
                format=pyaudio.paInt16,
                channels=1,
                rate=self.sample_rate,
                input=True,
                frames_per_buffer=4096
            )
            
            # å¯åŠ¨è¯†åˆ«çº¿ç¨‹
            recognition_thread = threading.Thread(
                target=self._stream_recognition_worker, 
                daemon=True
            )
            recognition_thread.start()
            
            logger.info("Voskæµå¼è¯†åˆ«å·²å¯åŠ¨")
            return True
            
        except Exception as e:
            logger.error(f"å¯åŠ¨æµå¼è¯†åˆ«å¤±è´¥: {e}")
            return False
    
    def stop_stream_recognition(self):
        """åœæ­¢æµå¼è¯†åˆ«"""
        self.is_listening = False
        
        if self.audio_stream:
            self.audio_stream.close()
            self.audio_stream = None
        
        logger.info("Voskæµå¼è¯†åˆ«å·²åœæ­¢")
    
    def _stream_recognition_worker(self):
        """æµå¼è¯†åˆ«å·¥ä½œçº¿ç¨‹"""
        logger.info("Voskæµå¼è¯†åˆ«çº¿ç¨‹å¯åŠ¨")
        
        while self.is_listening and self.audio_stream:
            try:
                # è¯»å–éŸ³é¢‘æ•°æ®
                data = self.audio_stream.read(4096, exception_on_overflow=False)
                
                # å¤„ç†éŸ³é¢‘
                if self.recognizer.AcceptWaveform(data):
                    # å®Œæ•´è¯†åˆ«ç»“æœ
                    result = json.loads(self.recognizer.Result())
                    text = result.get('text', '').strip()
                    
                    if text and self.recognition_callback:
                        self.recognition_callback(text)
                else:
                    # éƒ¨åˆ†è¯†åˆ«ç»“æœ
                    partial_result = json.loads(self.recognizer.PartialResult())
                    partial_text = partial_result.get('partial', '').strip()
                    
                    if partial_text and self.partial_callback:
                        self.partial_callback(partial_text)
                
            except Exception as e:
                logger.error(f"æµå¼è¯†åˆ«é”™è¯¯: {e}")
                time.sleep(0.1)
        
        logger.info("Voskæµå¼è¯†åˆ«çº¿ç¨‹ç»“æŸ")

# æµ‹è¯•å‡½æ•°
def test_vosk_recognizer():
    """æµ‹è¯•Voskè¯†åˆ«å™¨"""
    print("=== Voskè¯­éŸ³è¯†åˆ«æµ‹è¯• ===")
    
    recognizer = VoskRecognizer()
    
    if not recognizer.is_available:
        print("âŒ Voskä¸å¯ç”¨")
        return False
    
    print("âœ… Voskåˆå§‹åŒ–æˆåŠŸ")
    
    # æµ‹è¯•æµå¼è¯†åˆ«
    stream_recognizer = recognizer.create_stream_recognizer()
    
    if stream_recognizer:
        print("âœ… æµå¼è¯†åˆ«å™¨åˆ›å»ºæˆåŠŸ")
        
        def on_recognition(text):
            print(f"ğŸ¤ è¯†åˆ«ç»“æœ: {text}")
        
        def on_partial(text):
            print(f"ğŸ”„ éƒ¨åˆ†ç»“æœ: {text}")
        
        try:
            if stream_recognizer.start_stream_recognition(on_recognition, on_partial):
                print("ğŸ™ï¸ å¼€å§‹è¯´è¯æµ‹è¯•ï¼ŒæŒ‰Ctrl+Cåœæ­¢...")
                
                # ä¿æŒè¿è¡Œ
                while True:
                    time.sleep(1)
            else:
                print("âŒ æµå¼è¯†åˆ«å¯åŠ¨å¤±è´¥")
                
        except KeyboardInterrupt:
            print("\næ­£åœ¨åœæ­¢...")
            stream_recognizer.stop_stream_recognition()
            print("æµ‹è¯•ç»“æŸ")
    
    return True

if __name__ == "__main__":
    test_vosk_recognizer()
#!/usr/bin/python3
"""
å¢žå¼ºè¯­éŸ³æŽ§åˆ¶å™¨ - é›†æˆå”¤é†’è¯æ£€æµ‹ã€Whisperè¯­éŸ³è¯†åˆ«å’Œedge-ttsè¯­éŸ³åˆæˆ
æ”¯æŒAIå¯¹è¯æ¨¡å¼å’Œä¼ ç»Ÿå‘½ä»¤æŽ§åˆ¶æ¨¡å¼
"""

import speech_recognition as sr
import pyaudio
import threading
import time
import queue
import logging
import subprocess
import tempfile
import os
import wave
import json
import struct
from voice_control import VoiceController
from ai_conversation import AIConversationManager
from wake_word_detector import WakeWordDetector, SimpleWakeWordDetector
from whisper_integration import get_whisper_recognizer
from vosk_recognizer import VoskRecognizer
import asyncio
import edge_tts
import pygame

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, 
                   format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class EnhancedVoiceController(VoiceController):
    """å¢žå¼ºçš„è¯­éŸ³æŽ§åˆ¶å™¨ï¼Œæ”¯æŒAIå¯¹è¯å’Œå”¤é†’è¯æ£€æµ‹"""
    
    def __init__(self, robot=None, ai_conversation_manager=None, expression_controller=None, safety_manager=None):
        """
        åˆå§‹åŒ–å¢žå¼ºè¯­éŸ³æŽ§åˆ¶å™¨
        Args:
            robot: LOBOROBOTå®žä¾‹
            ai_conversation_manager: AIå¯¹è¯ç®¡ç†å™¨å®žä¾‹
            expression_controller: è¡¨æƒ…æŽ§åˆ¶å™¨å®žä¾‹
            safety_manager: å®‰å…¨ç®¡ç†å™¨å®žä¾‹
        """
        super().__init__(robot)
        
        self.ai_conversation_manager = ai_conversation_manager or AIConversationManager(robot, expression_controller, safety_manager)
        self.expression_controller = expression_controller
        self.safety_manager = safety_manager
        
        # å¯¹è¯æ¨¡å¼çŠ¶æ€
        self.conversation_mode = False
        self.wake_word_detected = False
        self.wake_word_active = False
        self.conversation_timeout = 30.0  # å¯¹è¯è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        self.last_interaction_time = time.time()
        
        # è¯­éŸ³åˆæˆè®¾ç½®
        self.tts_voice = "zh-CN-XiaoxiaoNeural"  # ä¸­æ–‡å¥³å£°
        self.tts_rate = "+0%"
        self.tts_volume = "+0%"
        
        # å”¤é†’è¯æ£€æµ‹å™¨
        self.wake_word_detector = None
        self.use_porcupine = self._initialize_wake_word_detection()
        
        # Whisperè¯­éŸ³è¯†åˆ«
        self.whisper_recognizer = None
        self.use_whisper = self._initialize_whisper()
        
        # Voskè¯­éŸ³è¯†åˆ«ï¼ˆä¸­æ–‡ç¦»çº¿ï¼‰
        self.vosk_recognizer = None
        self.use_vosk = self._initialize_vosk()
        
        # éŸ³é¢‘å¤„ç†é˜Ÿåˆ—
        self.audio_queue = queue.Queue()
        self.tts_queue = queue.Queue()
        
        # çº¿ç¨‹æŽ§åˆ¶
        self.tts_thread = None
        self.conversation_thread = None
        self.timeout_thread = None
        
        # éŸ³é¢‘æ’­æ”¾åˆå§‹åŒ–
        self._initialize_audio_playback()
        
        logger.info("å¢žå¼ºè¯­éŸ³æŽ§åˆ¶å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def _initialize_wake_word_detection(self):
        """åˆå§‹åŒ–å”¤é†’è¯æ£€æµ‹"""
        try:
            # é¦–å…ˆå°è¯•ä½¿ç”¨Porcupine
            self.wake_word_detector = WakeWordDetector()
            if self.wake_word_detector.porcupine:
                logger.info("ä½¿ç”¨Porcupineè¿›è¡Œå”¤é†’è¯æ£€æµ‹")
                return True
            else:
                # å¤‡é€‰ï¼šä½¿ç”¨ç®€å•æ£€æµ‹å™¨
                self.wake_word_detector = SimpleWakeWordDetector(["å–µå–µå°è½¦", "å°è½¦", "æœºå™¨äºº"])
                logger.info("ä½¿ç”¨ç®€å•æ£€æµ‹å™¨è¿›è¡Œå”¤é†’è¯æ£€æµ‹")
                return False
        except Exception as e:
            logger.error(f"å”¤é†’è¯æ£€æµ‹åˆå§‹åŒ–å¤±è´¥: {e}")
            self.wake_word_detector = None
            return False
    
    def _initialize_whisper(self):
        """åˆå§‹åŒ–Whisperè¯­éŸ³è¯†åˆ«"""
        try:
            self.whisper_recognizer = get_whisper_recognizer("base")
            if self.whisper_recognizer.model:
                logger.info("Whisperè¯­éŸ³è¯†åˆ«åˆå§‹åŒ–æˆåŠŸ")
                return True
            else:
                logger.warning("Whisperåˆå§‹åŒ–å¤±è´¥ï¼Œå°†ä½¿ç”¨å…¶ä»–è¯†åˆ«æ–¹å¼")
                return False
        except Exception as e:
            logger.warning(f"Whisperä¸å¯ç”¨ï¼Œè·³è¿‡æ¨¡åž‹åŠ è½½")
            return False
    
    def _initialize_vosk(self):
        """åˆå§‹åŒ–Voskä¸­æ–‡è¯­éŸ³è¯†åˆ«"""
        try:
            self.vosk_recognizer = VoskRecognizer()
            if self.vosk_recognizer.is_available:
                logger.info("Voskä¸­æ–‡è¯­éŸ³è¯†åˆ«åˆå§‹åŒ–æˆåŠŸ")
                return True
            else:
                logger.warning("Voskåˆå§‹åŒ–å¤±è´¥ï¼Œå°†ä½¿ç”¨å…¶ä»–è¯†åˆ«æ–¹å¼")
                return False
        except Exception as e:
            logger.warning(f"Voskä¸å¯ç”¨: {e}")
            return False
    
    def _initialize_audio_playback(self):
        """åˆå§‹åŒ–éŸ³é¢‘æ’­æ”¾ç³»ç»Ÿ"""
        try:
            pygame.mixer.init(frequency=22050, size=-16, channels=2, buffer=512)
            logger.info("éŸ³é¢‘æ’­æ”¾ç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.error(f"éŸ³é¢‘æ’­æ”¾ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
    
    def start_conversation_mode(self):
        """å¯åŠ¨AIå¯¹è¯æ¨¡å¼"""
        if not self.ai_conversation_manager:
            logger.error("AIå¯¹è¯ç®¡ç†å™¨æœªåˆå§‹åŒ–")
            return False
            
        if not self.ai_conversation_manager.start_conversation_mode():
            logger.error("AIå¯¹è¯ç®¡ç†å™¨å¯åŠ¨å¤±è´¥")
            return False
        
        self.conversation_mode = True
        self.last_interaction_time = time.time()
        
        # å¯åŠ¨å”¤é†’è¯æ£€æµ‹
        if self.wake_word_detector and not self.wake_word_active:
            if self.wake_word_detector.start_detection(self._on_wake_word_detected):
                self.wake_word_active = True
                logger.info("å”¤é†’è¯æ£€æµ‹å·²å¯åŠ¨")
            else:
                logger.warning("å”¤é†’è¯æ£€æµ‹å¯åŠ¨å¤±è´¥")
        
        # å¯åŠ¨TTSå¤„ç†çº¿ç¨‹
        if not self.tts_thread or not self.tts_thread.is_alive():
            self.tts_thread = threading.Thread(target=self._tts_worker, daemon=True)
            self.tts_thread.start()
        
        # å¯åŠ¨å¯¹è¯å¤„ç†çº¿ç¨‹
        if not self.conversation_thread or not self.conversation_thread.is_alive():
            self.conversation_thread = threading.Thread(target=self._conversation_worker, daemon=True)
            self.conversation_thread.start()
        
        # å¯åŠ¨è¶…æ—¶æ£€æŸ¥çº¿ç¨‹
        if not self.timeout_thread or not self.timeout_thread.is_alive():
            self.timeout_thread = threading.Thread(target=self._timeout_worker, daemon=True)
            self.timeout_thread.start()
        
        logger.info("AIå¯¹è¯æ¨¡å¼å·²å¯åŠ¨")
        
        # æ’­æ”¾å¯åŠ¨æç¤ºéŸ³å¹¶æä¾›å³æ—¶éŸ³é¢‘ç¡®è®¤
        self.speak_text("ä½ å¥½ï¼æˆ‘æ˜¯åœ†æ»šæ»šï¼Œè¯´'å–µå–µå°è½¦'æ¥å”¤é†’æˆ‘å§~")
        
        return True
    
    def stop_conversation_mode(self):
        """åœæ­¢AIå¯¹è¯æ¨¡å¼"""
        self.conversation_mode = False
        self.wake_word_detected = False
        
        # åœæ­¢å”¤é†’è¯æ£€æµ‹
        if self.wake_word_detector and self.wake_word_active:
            self.wake_word_detector.stop_detection()
            self.wake_word_active = False
        
        if self.ai_conversation_manager:
            self.ai_conversation_manager.stop_conversation_mode()
        
        # æ¸…ç©ºé˜Ÿåˆ—
        self.clear_queues()
        
        logger.info("AIå¯¹è¯æ¨¡å¼å·²åœæ­¢")
        
        # æ’­æ”¾åœæ­¢æç¤ºéŸ³
        self.speak_text("å¯¹è¯æ¨¡å¼å·²å…³é—­ï¼Œå†è§~")
    
    def _on_wake_word_detected(self, keyword_index):
        """å”¤é†’è¯æ£€æµ‹å›žè°ƒ"""
        if not self.conversation_mode:
            return
            
        logger.info(f"ðŸŽ¤ æ£€æµ‹åˆ°å”¤é†’è¯ï¼ç´¢å¼•: {keyword_index}")
        logger.info("ðŸ¤– AIæ¡Œå® å·²å”¤é†’ï¼Œå‡†å¤‡å¼€å§‹å¯¹è¯...")
        
        self.wake_word_detected = True
        self.last_interaction_time = time.time()
        
        logger.info("âœ… å”¤é†’çŠ¶æ€å·²è®¾ç½®ï¼Œå¼€å§‹è¯­éŸ³äº¤äº’æ¨¡å¼")
        logger.info(f"æ£€æµ‹åˆ°å”¤é†’è¯ï¼Œç´¢å¼•: {keyword_index}")
        
        # æä¾›å³æ—¶éŸ³é¢‘ç¡®è®¤ï¼ˆåœ¨1ç§’å†…ï¼‰
        self.speak_text("æˆ‘åœ¨å¬ï¼Œè¯·è¯´~", priority=True)
        
        # å¦‚æžœæœ‰è¡¨æƒ…æŽ§åˆ¶å™¨ï¼Œæ˜¾ç¤ºè†å¬çŠ¶æ€
        if self.expression_controller:
            self.expression_controller.show_listening_animation()
    
    def _timeout_worker(self):
        """è¶…æ—¶æ£€æŸ¥å·¥ä½œçº¿ç¨‹"""
        while self.conversation_mode:
            try:
                current_time = time.time()
                if (self.wake_word_detected and 
                    current_time - self.last_interaction_time > self.conversation_timeout):
                    
                    logger.info("å¯¹è¯è¶…æ—¶ï¼Œè¿”å›žå¾…æœºæ¨¡å¼")
                    self.wake_word_detected = False
                    
                    # å¦‚æžœæœ‰è¡¨æƒ…æŽ§åˆ¶å™¨ï¼Œæ˜¾ç¤ºç©ºé—²çŠ¶æ€
                    if self.expression_controller:
                        self.expression_controller.show_idle_animation()
                
                time.sleep(5)  # æ¯5ç§’æ£€æŸ¥ä¸€æ¬¡
                
            except Exception as e:
                logger.error(f"è¶…æ—¶æ£€æŸ¥é”™è¯¯: {e}")
                time.sleep(5)

    def listen_continuously(self):
        """æŒç»­ç›‘å¬è¯­éŸ³å‘½ä»¤å’Œå¯¹è¯"""
        if not self.microphone:
            logger.error("éº¦å…‹é£Žæœªåˆå§‹åŒ–ï¼Œæ— æ³•å¼€å§‹è¯­éŸ³è¯†åˆ«")
            return
            
        self.is_listening = True
        logger.info("å¼€å§‹è¯­éŸ³è¯†åˆ«ç›‘å¬...")
        
        # è®¾ç½®è¯†åˆ«å™¨å‚æ•°
        self.recognizer.energy_threshold = 300
        self.recognizer.pause_threshold = 0.8
        self.recognizer.timeout = 1
        
        while self.is_listening:
            try:
                # åªæœ‰åœ¨å”¤é†’çŠ¶æ€ä¸‹æ‰è¿›è¡Œè¯­éŸ³è¯†åˆ«
                if self.conversation_mode and self.wake_word_detected:
                    with self.microphone as source:
                        logger.debug("æ­£åœ¨ç›‘å¬å¯¹è¯...")
                        # ç›‘å¬éŸ³é¢‘ï¼Œå¯¹è¯æ¨¡å¼ä¸‹å»¶é•¿ç›‘å¬æ—¶é—´
                        audio = self.recognizer.listen(source, timeout=2, phrase_time_limit=8)
                    
                    # å°†éŸ³é¢‘æ”¾å…¥å¤„ç†é˜Ÿåˆ—
                    self.audio_queue.put(audio)
                else:
                    # éžå¯¹è¯æ¨¡å¼æˆ–æœªå”¤é†’æ—¶ï¼ŒçŸ­æš‚ä¼‘çœ 
                    time.sleep(0.1)
                
            except sr.WaitTimeoutError:
                # è¶…æ—¶æ˜¯æ­£å¸¸çš„ï¼Œç»§ç»­ç›‘å¬
                pass
            except Exception as e:
                logger.error(f"ç›‘å¬é”™è¯¯: {e}")
                time.sleep(1)
    
    def _conversation_worker(self):
        """å¯¹è¯å¤„ç†å·¥ä½œçº¿ç¨‹"""
        while self.conversation_mode:
            try:
                # ä»Žé˜Ÿåˆ—èŽ·å–éŸ³é¢‘
                audio = self.audio_queue.get(timeout=1)
                
                # å¤„ç†éŸ³é¢‘
                if self.conversation_mode and self.wake_word_detected:
                    self._process_conversation_audio(audio)
                elif not self.conversation_mode:
                    # ä¼ ç»Ÿå‘½ä»¤æ¨¡å¼
                    self._process_audio(audio)
                
                self.audio_queue.task_done()
                
            except queue.Empty:
                continue
            except Exception as e:
                logger.error(f"å¯¹è¯å¤„ç†é”™è¯¯: {e}")
    
    def _process_conversation_audio(self, audio):
        """å¤„ç†å¯¹è¯æ¨¡å¼ä¸‹çš„éŸ³é¢‘"""
        try:
            logger.info("ðŸŽ™ï¸ å¼€å§‹å¤„ç†å½•éŸ³éŸ³é¢‘...")
            # æ˜¾ç¤ºæ€è€ƒçŠ¶æ€
            if self.expression_controller:
                self.expression_controller.show_thinking_animation()
            
            # è¯­éŸ³è¯†åˆ« - ä¼˜å…ˆçº§é¡ºåºï¼šVosk(ä¸­æ–‡) > Whisper > Google(åœ¨çº¿) > PocketSphinx(è‹±æ–‡)
            text = None
            
            # 1. ä¼˜å…ˆä½¿ç”¨Voskè¿›è¡Œä¸­æ–‡è¯†åˆ«
            if self.use_vosk and self.vosk_recognizer:
                try:
                    text = self.vosk_recognizer.recognize_from_speech_recognition_audio(audio)
                    if text:
                        logger.info(f"Voskè¯†åˆ«æˆåŠŸ: {text}")
                except Exception as e:
                    logger.debug(f"Voskè¯†åˆ«å¤±è´¥: {e}")
            
            # 2. å¤‡é€‰ï¼šä½¿ç”¨Whisper
            if not text and self.use_whisper and self.whisper_recognizer:
                try:
                    text = self._whisper_recognize_from_audio(audio)
                    if text:
                        logger.info(f"Whisperè¯†åˆ«æˆåŠŸ: {text}")
                except Exception as e:
                    logger.debug(f"Whisperè¯†åˆ«å¤±è´¥: {e}")
            
            # 3. å¤‡é€‰ï¼šä½¿ç”¨Googleåœ¨çº¿è¯†åˆ«ï¼ˆæ”¯æŒä¸­æ–‡ï¼‰
            if not text:
                try:
                    text = self.recognizer.recognize_google(audio, language='zh-CN')
                    if text:
                        logger.info(f"Googleè¯†åˆ«æˆåŠŸ: {text}")
                except Exception as e:
                    logger.debug(f"Googleè¯†åˆ«å¤±è´¥: {e}")
            
            # 4. æœ€åŽå¤‡é€‰ï¼šä½¿ç”¨PocketSphinxï¼ˆè‹±æ–‡ï¼‰
            if not text:
                try:
                    text = self.recognizer.recognize_sphinx(audio)
                    if text:
                        logger.info(f"PocketSphinxè¯†åˆ«æˆåŠŸ: {text}")
                except Exception as e:
                    logger.debug(f"PocketSphinxè¯†åˆ«å¤±è´¥: {e}")
            
            if not text or not text.strip():
                logger.debug("æœªè¯†åˆ«åˆ°æœ‰æ•ˆè¯­éŸ³")
                return
                
            text = text.strip()
            logger.info(f"è¯†åˆ«åˆ°è¯­éŸ³: '{text}'")
            
            # æ›´æ–°äº¤äº’æ—¶é—´
            self.last_interaction_time = time.time()
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯ç»“æŸå¯¹è¯çš„å‘½ä»¤
            if any(word in text for word in ['å†è§', 'ç»“æŸå¯¹è¯', 'åœæ­¢', 'é€€å‡º', 'ç¡è§‰']):
                self.wake_word_detected = False
                self.speak_text("å¥½çš„ï¼Œæœ‰éœ€è¦å†å«æˆ‘~")
                
                if self.expression_controller:
                    self.expression_controller.show_idle_animation()
                return
            
            # å‘é€åˆ°AIå¯¹è¯ç®¡ç†å™¨
            context = self.ai_conversation_manager.process_user_input(text)
            
            if context and context.ai_response:
                # æ’­æ”¾AIå›žå¤
                self.speak_text(context.ai_response)
                
                # æ ¹æ®æƒ…æ„Ÿæ‰§è¡Œç›¸åº”åŠ¨ä½œ
                self._execute_emotional_action(context.emotion_detected)
            else:
                # å¤„ç†å¤±è´¥æ—¶çš„åé¦ˆ
                self.speak_text("æŠ±æ­‰ï¼Œæˆ‘æ²¡æœ‰ç†è§£ï¼Œè¯·å†è¯´ä¸€é~")
            
        except sr.UnknownValueError:
            logger.debug("æ— æ³•ç†è§£éŸ³é¢‘")
        except sr.RequestError as e:
            logger.error(f"è¯­éŸ³è¯†åˆ«æœåŠ¡é”™è¯¯: {e}")
            self.speak_text("è¯­éŸ³è¯†åˆ«å‡ºçŽ°é—®é¢˜ï¼Œè¯·ç¨åŽå†è¯•~")
        except Exception as e:
            logger.error(f"å¯¹è¯éŸ³é¢‘å¤„ç†é”™è¯¯: {e}")
            self.speak_text("å¤„ç†å‡ºçŽ°é—®é¢˜ï¼Œè¯·ç¨åŽå†è¯•~")
    
    def _whisper_recognize_from_audio(self, audio):
        """ä½¿ç”¨Whisperè¿›è¡Œè¯­éŸ³è¯†åˆ«"""
        try:
            if not self.whisper_recognizer:
                return None
                
            # å°†SpeechRecognitionçš„AudioDataè½¬æ¢ä¸ºéŸ³é¢‘æ•°æ®
            wav_data = audio.get_wav_data()
            
            # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
            with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as temp_file:
                temp_file.write(wav_data)
                temp_file_path = temp_file.name
            
            try:
                # ä½¿ç”¨Whisperè¯†åˆ«
                text = self.whisper_recognizer.recognize_audio_file(temp_file_path)
                return text
            finally:
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                if os.path.exists(temp_file_path):
                    os.unlink(temp_file_path)
            
        except Exception as e:
            logger.error(f"Whisperè¯†åˆ«å¤±è´¥: {e}")
            return None
    
    def _execute_emotional_action(self, emotion):
        """æ ¹æ®æƒ…æ„Ÿæ‰§è¡Œç›¸åº”çš„æœºå™¨äººåŠ¨ä½œ"""
        if not self.robot:
            return
            
        try:
            if emotion == 'happy':
                # å¼€å¿ƒæ—¶è½¬ä¸ªåœˆ
                self.robot.turnRight(30, 0.5)
                self.robot.turnLeft(30, 0.5)
                
            elif emotion == 'excited':
                # å…´å¥‹æ—¶å¿«é€Ÿå·¦å³æ‘†åŠ¨
                self.robot.turnLeft(40, 0.2)
                self.robot.turnRight(40, 0.2)
                self.robot.turnLeft(40, 0.2)
                
            elif emotion == 'sad':
                # æ‚²ä¼¤æ—¶ç¼“æ…¢åŽé€€
                self.robot.t_down(20, 0.5)
                
            elif emotion == 'confused':
                # å›°æƒ‘æ—¶å·¦å³æ‘‡å¤´
                self.robot.turnLeft(25, 0.3)
                self.robot.turnRight(25, 0.3)
                
            elif emotion == 'thinking':
                # æ€è€ƒæ—¶è½»å¾®æ‘†åŠ¨
                self.robot.moveLeft(15, 0.2)
                self.robot.moveRight(15, 0.2)
                
        except Exception as e:
            logger.error(f"æ‰§è¡Œæƒ…æ„ŸåŠ¨ä½œå¤±è´¥: {e}")
    
    def speak_text(self, text, priority=False):
        """å°†æ–‡æœ¬è½¬æ¢ä¸ºè¯­éŸ³å¹¶æ’­æ”¾"""
        if text:
            if priority:
                # ä¼˜å…ˆçº§é«˜çš„æ¶ˆæ¯æ’å…¥é˜Ÿåˆ—å‰ç«¯
                temp_queue = queue.Queue()
                temp_queue.put(text)
                while not self.tts_queue.empty():
                    temp_queue.put(self.tts_queue.get())
                self.tts_queue = temp_queue
            else:
                self.tts_queue.put(text)
    
    def _tts_worker(self):
        """TTSå¤„ç†å·¥ä½œçº¿ç¨‹"""
        while self.conversation_mode or not self.tts_queue.empty():
            try:
                # ä»Žé˜Ÿåˆ—èŽ·å–æ–‡æœ¬
                text = self.tts_queue.get(timeout=1)
                
                # æ˜¾ç¤ºè¯´è¯åŠ¨ç”»
                if self.expression_controller:
                    # ä¼°ç®—è¯´è¯æ—¶é•¿
                    estimated_duration = len(text) * 0.15  # å¤§çº¦æ¯ä¸ªå­—0.15ç§’
                    threading.Thread(
                        target=self.expression_controller.animate_speaking,
                        args=(estimated_duration,),
                        daemon=True
                    ).start()
                
                # ä½¿ç”¨edge-ttsç”Ÿæˆè¯­éŸ³
                self._generate_and_play_speech(text)
                
                self.tts_queue.task_done()
                
            except queue.Empty:
                continue
            except Exception as e:
                logger.error(f"TTSå¤„ç†é”™è¯¯: {e}")
    
    def _generate_and_play_speech(self, text):
        """ç”Ÿæˆå¹¶æ’­æ”¾è¯­éŸ³"""
        try:
            # æ£€æŸ¥æ˜¯å¦åœ¨ç¦»çº¿æ¨¡å¼
            if self.safety_manager and self.safety_manager.safety_state.offline_mode_active:
                # ç¦»çº¿æ¨¡å¼ä¸‹ä½¿ç”¨ç®€å•çš„æ–‡æœ¬è¾“å‡º
                logger.info(f"ç¦»çº¿æ¨¡å¼TTS: {text}")
                return
            
            # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
            with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as temp_file:
                temp_file_path = temp_file.name
            
            # ä½¿ç”¨edge-ttsç”Ÿæˆè¯­éŸ³
            asyncio.run(self._async_generate_speech(text, temp_file_path))
            
            # æ’­æ”¾éŸ³é¢‘æ–‡ä»¶
            self._play_audio_file_pygame(temp_file_path)
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if os.path.exists(temp_file_path):
                os.unlink(temp_file_path)
            
        except Exception as e:
            logger.error(f"è¯­éŸ³ç”Ÿæˆæ’­æ”¾å¤±è´¥: {e}")
            
            # å¦‚æžœæœ‰å®‰å…¨ç®¡ç†å™¨ï¼Œè®°å½•TTSå¤±è´¥
            if self.safety_manager:
                self.safety_manager.handle_api_failure("tts_error", 0)
    
    async def _async_generate_speech(self, text, output_path):
        """å¼‚æ­¥ç”Ÿæˆè¯­éŸ³"""
        try:
            communicate = edge_tts.Communicate(
                text, 
                self.tts_voice,
                rate=self.tts_rate,
                volume=self.tts_volume
            )
            await communicate.save(output_path)
        except Exception as e:
            logger.error(f"edge-ttsè¯­éŸ³ç”Ÿæˆå¤±è´¥: {e}")
            raise
    
    def _play_audio_file_pygame(self, file_path):
        """ä½¿ç”¨pygameæ’­æ”¾éŸ³é¢‘æ–‡ä»¶"""
        try:
            pygame.mixer.music.load(file_path)
            pygame.mixer.music.play()
            
            # ç­‰å¾…æ’­æ”¾å®Œæˆ
            while pygame.mixer.music.get_busy():
                time.sleep(0.1)
                
        except Exception as e:
            logger.error(f"pygameéŸ³é¢‘æ’­æ”¾å¤±è´¥: {e}")
            # å¤‡é€‰æ–¹æ¡ˆ
            self._play_audio_file_system(file_path)
    
    def _play_audio_file_system(self, file_path):
        """ä½¿ç”¨ç³»ç»Ÿå‘½ä»¤æ’­æ”¾éŸ³é¢‘æ–‡ä»¶"""
        try:
            # é¦–å…ˆå°è¯•aplayï¼ˆæ ‘èŽ“æ´¾å¸¸ç”¨ï¼‰
            result = subprocess.run(['aplay', file_path], 
                                  capture_output=True, 
                                  timeout=10)
            if result.returncode == 0:
                return
        except:
            pass
        
        try:
            # å¤‡é€‰ï¼šä½¿ç”¨mpg123
            subprocess.run(['mpg123', file_path], 
                         check=True, 
                         capture_output=True,
                         timeout=10)
        except:
            try:
                # å¤‡é€‰ï¼šä½¿ç”¨ffplay
                subprocess.run(['ffplay', '-nodisp', '-autoexit', file_path], 
                             check=True, 
                             capture_output=True,
                             timeout=10)
            except:
                logger.error("æ— æ³•æ’­æ”¾éŸ³é¢‘æ–‡ä»¶ï¼Œè¯·å®‰è£…aplayã€mpg123æˆ–ffplay")
    
    def get_conversation_status(self):
        """èŽ·å–å¯¹è¯çŠ¶æ€"""
        return {
            'conversation_mode': self.conversation_mode,
            'wake_word_detected': self.wake_word_detected,
            'wake_word_active': self.wake_word_active,
            'ai_manager_active': self.ai_conversation_manager.is_active() if self.ai_conversation_manager else False,
            'tts_queue_size': self.tts_queue.qsize(),
            'audio_queue_size': self.audio_queue.qsize(),
            'use_whisper': self.use_whisper,
            'use_porcupine': self.use_porcupine,
            'last_interaction': self.last_interaction_time
        }
    
    def set_tts_voice(self, voice_name):
        """è®¾ç½®TTSè¯­éŸ³"""
        available_voices = [
            "zh-CN-XiaoxiaoNeural",  # å¥³å£°
            "zh-CN-YunxiNeural",     # ç”·å£°
            "zh-CN-YunyangNeural",   # ç”·å£°
            "zh-CN-XiaoyiNeural",    # å¥³å£°
            "zh-CN-YunjianNeural"    # ç”·å£°
        ]
        
        if voice_name in available_voices:
            self.tts_voice = voice_name
            logger.info(f"TTSè¯­éŸ³è®¾ç½®ä¸º: {voice_name}")
        else:
            logger.warning(f"ä¸æ”¯æŒçš„è¯­éŸ³: {voice_name}ï¼Œå¯ç”¨è¯­éŸ³: {available_voices}")
    
    def set_tts_parameters(self, rate=None, volume=None):
        """è®¾ç½®TTSå‚æ•°"""
        if rate is not None:
            self.tts_rate = rate
            logger.info(f"TTSè¯­é€Ÿè®¾ç½®ä¸º: {rate}")
        
        if volume is not None:
            self.tts_volume = volume
            logger.info(f"TTSéŸ³é‡è®¾ç½®ä¸º: {volume}")
    
    def clear_queues(self):
        """æ¸…ç©ºæ‰€æœ‰é˜Ÿåˆ—"""
        while not self.audio_queue.empty():
            try:
                self.audio_queue.get_nowait()
            except queue.Empty:
                break
                
        while not self.tts_queue.empty():
            try:
                self.tts_queue.get_nowait()
            except queue.Empty:
                break
        
        logger.info("éŸ³é¢‘å’ŒTTSé˜Ÿåˆ—å·²æ¸…ç©º")
    
    def force_wake_up(self):
        """å¼ºåˆ¶å”¤é†’ï¼ˆç”¨äºŽæµ‹è¯•æˆ–æ‰‹åŠ¨æ¿€æ´»ï¼‰"""
        if self.conversation_mode:
            self.wake_word_detected = True
            self.last_interaction_time = time.time()
            self.speak_text("æˆ‘è¢«å”¤é†’äº†ï¼Œè¯·è¯´~", priority=True)
            
            if self.expression_controller:
                self.expression_controller.show_listening_animation()
            
            logger.info("å¼ºåˆ¶å”¤é†’æˆåŠŸ")
            return True
        else:
            logger.warning("å¯¹è¯æ¨¡å¼æœªå¯åŠ¨ï¼Œæ— æ³•å¼ºåˆ¶å”¤é†’")
            return False
    
    def get_available_voices(self):
        """èŽ·å–å¯ç”¨çš„TTSè¯­éŸ³åˆ—è¡¨"""
        return [
            {"name": "zh-CN-XiaoxiaoNeural", "description": "æ™“æ™“ - å¥³å£°"},
            {"name": "zh-CN-YunxiNeural", "description": "äº‘å¸Œ - ç”·å£°"},
            {"name": "zh-CN-YunyangNeural", "description": "äº‘æ‰¬ - ç”·å£°"},
            {"name": "zh-CN-XiaoyiNeural", "description": "æ™“ä¼Š - å¥³å£°"},
            {"name": "zh-CN-YunjianNeural", "description": "äº‘å¥ - ç”·å£°"}
        ]

# æµ‹è¯•å’Œæ¼”ç¤ºå‡½æ•°
def test_enhanced_voice_control():
    """æµ‹è¯•å¢žå¼ºè¯­éŸ³æŽ§åˆ¶åŠŸèƒ½"""
    print("=== å¢žå¼ºè¯­éŸ³æŽ§åˆ¶å™¨æµ‹è¯• ===")
    
    # åˆ›å»ºå¢žå¼ºè¯­éŸ³æŽ§åˆ¶å™¨
    enhanced_voice = EnhancedVoiceController()
    
    try:
        # æ˜¾ç¤ºç³»ç»ŸçŠ¶æ€
        status = enhanced_voice.get_conversation_status()
        print(f"ç³»ç»ŸçŠ¶æ€: {json.dumps(status, indent=2, ensure_ascii=False)}")
        
        # æ˜¾ç¤ºå¯ç”¨è¯­éŸ³
        voices = enhanced_voice.get_available_voices()
        print("\nå¯ç”¨è¯­éŸ³:")
        for voice in voices:
            print(f"  - {voice['name']}: {voice['description']}")
        
        # å¯åŠ¨å¯¹è¯æ¨¡å¼
        if enhanced_voice.start_conversation_mode():
            print("\nå¯¹è¯æ¨¡å¼å¯åŠ¨æˆåŠŸ")
            print("åŠŸèƒ½è¯´æ˜Ž:")
            print("- è¯´'å–µå–µå°è½¦'æ¥å”¤é†’æœºå™¨äºº")
            print("- å”¤é†’åŽå¯ä»¥è¿›è¡Œè‡ªç„¶å¯¹è¯")
            print("- è¯´'å†è§'æ¥ç»“æŸå¯¹è¯")
            print("- 30ç§’æ— äº¤äº’ä¼šè‡ªåŠ¨è¿”å›žå¾…æœº")
            print("- æŒ‰Ctrl+Cé€€å‡ºæµ‹è¯•")
            
            # å¯åŠ¨ç›‘å¬
            listen_thread = threading.Thread(target=enhanced_voice.listen_continuously, daemon=True)
            listen_thread.start()
            
            # ä¿æŒç¨‹åºè¿è¡Œ
            while True:
                time.sleep(1)
                
        else:
            print("å¯¹è¯æ¨¡å¼å¯åŠ¨å¤±è´¥")
            
    except KeyboardInterrupt:
        print("\næ­£åœ¨åœæ­¢...")
        enhanced_voice.stop()
        enhanced_voice.stop_conversation_mode()
        print("æµ‹è¯•ç»“æŸ")

def demo_tts_voices():
    """æ¼”ç¤ºä¸åŒTTSè¯­éŸ³"""
    print("=== TTSè¯­éŸ³æ¼”ç¤º ===")
    
    enhanced_voice = EnhancedVoiceController()
    
    # å¯åŠ¨TTSçº¿ç¨‹
    enhanced_voice.conversation_mode = True
    enhanced_voice.tts_thread = threading.Thread(target=enhanced_voice._tts_worker, daemon=True)
    enhanced_voice.tts_thread.start()
    
    voices = enhanced_voice.get_available_voices()
    test_text = "ä½ å¥½ï¼Œæˆ‘æ˜¯åœ†æ»šæ»šï¼Œå¾ˆé«˜å…´è®¤è¯†ä½ ï¼"
    
    for voice in voices:
        print(f"\næµ‹è¯•è¯­éŸ³: {voice['description']}")
        enhanced_voice.set_tts_voice(voice['name'])
        enhanced_voice.speak_text(test_text)
        time.sleep(3)  # ç­‰å¾…æ’­æ”¾å®Œæˆ
    
    enhanced_voice.conversation_mode = False
    print("\nè¯­éŸ³æ¼”ç¤ºå®Œæˆ")

if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1 and sys.argv[1] == "demo":
        demo_tts_voices()
    else:
        test_enhanced_voice_control()
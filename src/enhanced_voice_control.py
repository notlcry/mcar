#!/usr/bin/python3
"""
å¢žå¼ºè¯­éŸ³æŽ§åˆ¶å™¨ - é›†æˆå”¤é†’è¯æ£€æµ‹ã€Whisperè¯­éŸ³è¯†åˆ«å’Œedge-ttsè¯­éŸ³åˆæˆ
æ”¯æŒAIå¯¹è¯æ¨¡å¼å’Œä¼ ç»Ÿå‘½ä»¤æŽ§åˆ¶æ¨¡å¼
"""

import speech_recognition as sr
import pyaudio
import threading
import time
import queue
import logging
import subprocess
import tempfile
import os
import wave
import json
import struct
from voice_control import VoiceController
from ai_conversation import AIConversationManager
from wake_word_detector import WakeWordDetector, SimpleWakeWordDetector
# å¯¼å…¥ä¿®å¤ç‰ˆå”¤é†’è¯æ£€æµ‹å™¨
from simple_wake_word_test import test_simple_wake_word
import simple_wake_word_test
from whisper_integration import get_whisper_recognizer
from vosk_recognizer import VoskRecognizer
import asyncio
import edge_tts
import pygame
import re
from azure_tts import AzureTTS

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, 
                   format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class EnhancedVoiceController(VoiceController):
    """å¢žå¼ºçš„è¯­éŸ³æŽ§åˆ¶å™¨ï¼Œæ”¯æŒAIå¯¹è¯å’Œå”¤é†’è¯æ£€æµ‹"""
    
    def __init__(self, robot=None, ai_conversation_manager=None, expression_controller=None, safety_manager=None, test_mode=False):
        """
        åˆå§‹åŒ–å¢žå¼ºè¯­éŸ³æŽ§åˆ¶å™¨
        Args:
            robot: LOBOROBOTå®žä¾‹
            ai_conversation_manager: AIå¯¹è¯ç®¡ç†å™¨å®žä¾‹
            expression_controller: è¡¨æƒ…æŽ§åˆ¶å™¨å®žä¾‹
            safety_manager: å®‰å…¨ç®¡ç†å™¨å®žä¾‹
            test_mode: æµ‹è¯•æ¨¡å¼ï¼Œç¦ç”¨éŸ³é¢‘æµä»¥é¿å…æ®µé”™è¯¯
        """
        super().__init__(robot)
        
        # æµ‹è¯•æ¨¡å¼æ ‡å¿—
        self.test_mode = test_mode
        
        self.ai_conversation_manager = ai_conversation_manager or AIConversationManager(robot, expression_controller, safety_manager)
        self.expression_controller = expression_controller
        self.safety_manager = safety_manager
        
        # æ˜¾ç¤ºæŽ§åˆ¶å™¨ - é›†æˆOLEDæ˜¾ç¤ºå™¨
        self.display_controller = None
        self._initialize_display_controller()
        
        # å¯¹è¯æ¨¡å¼çŠ¶æ€
        self.conversation_mode = False
        self.wake_word_detected = False
        self.wake_word_active = False
        self.conversation_timeout = 30.0  # å¯¹è¯è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        self.last_interaction_time = time.time()
        
        # éŸ³é¢‘æµæŽ§åˆ¶ï¼ˆé˜²å›žéŸ³ï¼‰
        self.is_playing_audio = False
        self.audio_lock = threading.Lock()
        self.recording_paused = False
        
        # è¯­éŸ³åˆæˆè®¾ç½®
        self.tts_voice = "zh-CN-XiaoxiaoNeural"  # ä¸­æ–‡å¥³å£°
        self.tts_rate = "+0%"
        self.tts_volume = "+0%"
        
        # Azure TTSå¤‡é€‰æ–¹æ¡ˆ
        self.azure_tts = None
        self._initialize_azure_tts()
        
        # å”¤é†’è¯æ£€æµ‹å™¨
        self.wake_word_detector = None
        self.use_porcupine = self._initialize_wake_word_detection()
        
        # Whisperè¯­éŸ³è¯†åˆ«
        self.whisper_recognizer = None
        self.use_whisper = self._initialize_whisper()
        
        # Voskè¯­éŸ³è¯†åˆ«ï¼ˆä¸­æ–‡ç¦»çº¿ï¼‰
        self.vosk_recognizer = None
        self.use_vosk = self._initialize_vosk()
        
        # éŸ³é¢‘å¤„ç†é˜Ÿåˆ—
        self.audio_queue = queue.Queue()
        self.tts_queue = queue.Queue()
        
        # çº¿ç¨‹æŽ§åˆ¶
        self.tts_thread = None
        self.conversation_thread = None
        self.timeout_thread = None
        
        # éŸ³é¢‘æ’­æ”¾åˆå§‹åŒ–
        self._initialize_audio_playback()
        
        # æ˜¾ç¤ºè¯­éŸ³è¯†åˆ«å¼•æ“ŽçŠ¶æ€æ€»ç»“
        logger.info("ðŸŽ¤ å¢žå¼ºè¯­éŸ³æŽ§åˆ¶å™¨åˆå§‹åŒ–å®Œæˆ")
        logger.info("=" * 50)
        logger.info("ðŸ“Š è¯­éŸ³è¯†åˆ«å¼•æ“ŽçŠ¶æ€:")
        logger.info(f"   ðŸ‡¨ðŸ‡³ Vosk (ä¸­æ–‡ç¦»çº¿):     {'âœ… å¯ç”¨' if self.use_vosk else 'âŒ ä¸å¯ç”¨'}")
        logger.info(f"   ðŸŒ Whisper (å¤šè¯­è¨€):     {'âœ… å¯ç”¨' if self.use_whisper else 'âŒ ä¸å¯ç”¨'}")
        logger.info(f"   ðŸŒ Google (åœ¨çº¿):        âœ… å¯ç”¨")
        logger.info(f"   ðŸ‡ºðŸ‡¸ PocketSphinx (è‹±æ–‡): âœ… å¯ç”¨")
        logger.info(f"   ðŸ–¥ï¸ OLEDæ˜¾ç¤ºå™¨:         {'âœ… å¯ç”¨' if self.display_controller and self.display_controller.is_available() else 'âŒ ä¸å¯ç”¨'}")
        logger.info("=" * 50)
    
    def _initialize_wake_word_detection(self):
        """åˆå§‹åŒ–å”¤é†’è¯æ£€æµ‹"""
        try:
            # é¦–å…ˆå°è¯•ä½¿ç”¨Porcupine
            self.wake_word_detector = WakeWordDetector()
            if self.wake_word_detector.porcupine:
                logger.info("ä½¿ç”¨Porcupineè¿›è¡Œå”¤é†’è¯æ£€æµ‹")
                return True
            else:
                # å¤‡é€‰ï¼šä½¿ç”¨ç®€å•æ£€æµ‹å™¨
                self.wake_word_detector = SimpleWakeWordDetector(["å¿«å¿«", "å°è½¦", "æœºå™¨äºº"])
                logger.info("ä½¿ç”¨ç®€å•æ£€æµ‹å™¨è¿›è¡Œå”¤é†’è¯æ£€æµ‹")
                return False
        except Exception as e:
            logger.error(f"å”¤é†’è¯æ£€æµ‹åˆå§‹åŒ–å¤±è´¥: {e}")
            self.wake_word_detector = None
            return False
    
    def _initialize_whisper(self):
        """åˆå§‹åŒ–Whisperè¯­éŸ³è¯†åˆ«"""
        try:
            self.whisper_recognizer = get_whisper_recognizer("base")
            if self.whisper_recognizer.model:
                logger.info("Whisperè¯­éŸ³è¯†åˆ«åˆå§‹åŒ–æˆåŠŸ")
                return True
            else:
                logger.warning("Whisperåˆå§‹åŒ–å¤±è´¥ï¼Œå°†ä½¿ç”¨å…¶ä»–è¯†åˆ«æ–¹å¼")
                return False
        except Exception as e:
            logger.warning(f"Whisperä¸å¯ç”¨ï¼Œè·³è¿‡æ¨¡åž‹åŠ è½½")
            return False
    
    def _initialize_vosk(self):
        """åˆå§‹åŒ–Voskä¸­æ–‡è¯­éŸ³è¯†åˆ«"""
        logger.info("ðŸŽ¤ æ­£åœ¨åˆå§‹åŒ–Voskä¸­æ–‡è¯­éŸ³è¯†åˆ«...")
        try:
            self.vosk_recognizer = VoskRecognizer()
            if self.vosk_recognizer.is_available:
                logger.info("ðŸŽ‰ Voskä¸­æ–‡è¯­éŸ³è¯†åˆ«åˆå§‹åŒ–æˆåŠŸï¼")
                logger.info("ðŸ“‹ è¯­éŸ³è¯†åˆ«ä¼˜å…ˆçº§: Vosk(ä¸­æ–‡) > Whisper > Google > PocketSphinx")
                return True
            else:
                logger.warning("âŒ Voskåˆå§‹åŒ–å¤±è´¥ï¼Œå°†ä½¿ç”¨å…¶ä»–è¯†åˆ«æ–¹å¼")
                return False
        except Exception as e:
            logger.warning(f"âŒ Voskä¸å¯ç”¨: {e}")
            return False
    
    def _initialize_display_controller(self):
        """åˆå§‹åŒ–æ˜¾ç¤ºæŽ§åˆ¶å™¨"""
        try:
            from display_controller import DisplayController
            self.display_controller = DisplayController()
            
            if self.display_controller.is_available():
                self.display_controller.start()
                logger.info("ðŸ–¥ï¸ OLEDæ˜¾ç¤ºå™¨åˆå§‹åŒ–æˆåŠŸ")
                
                # å¦‚æžœæœ‰è¡¨æƒ…æŽ§åˆ¶å™¨ï¼Œå…³è”æ˜¾ç¤ºå™¨
                if self.expression_controller:
                    self.expression_controller.set_display_controller(self.display_controller)
            else:
                logger.info("âš ï¸ OLEDæ˜¾ç¤ºå™¨ä¸å¯ç”¨ï¼Œç»§ç»­è¿è¡Œ")
                self.display_controller = None
                
        except ImportError:
            logger.info("âš ï¸ æ˜¾ç¤ºæŽ§åˆ¶å™¨æ¨¡å—ä¸å¯ç”¨")
            self.display_controller = None
        except Exception as e:
            logger.warning(f"æ˜¾ç¤ºæŽ§åˆ¶å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            self.display_controller = None
    
    def _initialize_azure_tts(self):
        """åˆå§‹åŒ–Azure TTSå¤‡é€‰æ–¹æ¡ˆ"""
        try:
            # ä»ŽçŽ¯å¢ƒå˜é‡èŽ·å–Azureé…ç½®
            azure_endpoint = os.getenv("AZURE_TTS_ENDPOINT")
            azure_api_key = os.getenv("AZURE_TTS_API_KEY") 
            azure_region = os.getenv("AZURE_TTS_REGION", "eastus")
            
            if not azure_endpoint or not azure_api_key:
                logger.info("Azure TTSé…ç½®æœªè®¾ç½®ï¼Œè·³è¿‡åˆå§‹åŒ–")
                self.azure_tts = None
                return False
            
            # Azure Speeché…ç½®
            azure_config = {
                "endpoint": azure_endpoint,
                "api_key": azure_api_key,
                "region": azure_region,
                "voice": "zh-CN-YunyangNeural",
                "rate": "medium",
                "output_format": "audio-24khz-48kbitrate-mono-mp3"
            }
            
            self.azure_tts = AzureTTS(**azure_config)
            logger.info("ðŸŽ¤ Azure TTSä¸»è¦æ–¹æ¡ˆåˆå§‹åŒ–æˆåŠŸ")
            return True
            
        except Exception as e:
            logger.warning(f"Azure TTSåˆå§‹åŒ–å¤±è´¥: {e}")
            self.azure_tts = None
            return False
    
    def _initialize_audio_playback(self):
        """åˆå§‹åŒ–éŸ³é¢‘æ’­æ”¾ç³»ç»Ÿ"""
        try:
            pygame.mixer.init(frequency=22050, size=-16, channels=2, buffer=512)
            logger.info("éŸ³é¢‘æ’­æ”¾ç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.error(f"éŸ³é¢‘æ’­æ”¾ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
    
    def start_conversation_mode(self):
        """å¯åŠ¨AIå¯¹è¯æ¨¡å¼"""
        if not self.ai_conversation_manager:
            logger.error("AIå¯¹è¯ç®¡ç†å™¨æœªåˆå§‹åŒ–")
            return False
            
        if not self.ai_conversation_manager.start_conversation_mode():
            logger.error("AIå¯¹è¯ç®¡ç†å™¨å¯åŠ¨å¤±è´¥")
            return False
        
        self.conversation_mode = True
        self.last_interaction_time = time.time()
        
        # å¯åŠ¨å”¤é†’è¯æ£€æµ‹ï¼ˆæµ‹è¯•æ¨¡å¼ä¸‹è·³è¿‡ï¼‰
        if not self.test_mode and self.wake_word_detector and not self.wake_word_active:
            if self.wake_word_detector.start_detection(self._on_wake_word_detected):
                self.wake_word_active = True
                logger.info("å”¤é†’è¯æ£€æµ‹å·²å¯åŠ¨")
            else:
                logger.warning("å”¤é†’è¯æ£€æµ‹å¯åŠ¨å¤±è´¥")
        elif self.test_mode:
            logger.info("æµ‹è¯•æ¨¡å¼ï¼šè·³è¿‡å”¤é†’è¯æ£€æµ‹å¯åŠ¨")
        
        # å¯åŠ¨TTSå¤„ç†çº¿ç¨‹
        if not self.tts_thread or not self.tts_thread.is_alive():
            self.tts_thread = threading.Thread(target=self._tts_worker, daemon=True)
            self.tts_thread.start()
        
        # å¯åŠ¨çŠ¶æ€æœºçº¿ç¨‹ï¼ˆæµ‹è¯•æ¨¡å¼ä¸‹ä½¿ç”¨å®‰å…¨ç‰ˆæœ¬ï¼‰
        if not self.conversation_thread or not self.conversation_thread.is_alive():
            if self.test_mode:
                self.conversation_thread = threading.Thread(target=self._safe_state_machine_worker, daemon=True)
                logger.info("æµ‹è¯•æ¨¡å¼ï¼šä½¿ç”¨å®‰å…¨çŠ¶æ€æœº")
            else:
                self.conversation_thread = threading.Thread(target=self._state_machine_worker, daemon=True)
            self.conversation_thread.start()
        
        # å¯åŠ¨è¶…æ—¶æ£€æŸ¥çº¿ç¨‹
        if not self.timeout_thread or not self.timeout_thread.is_alive():
            self.timeout_thread = threading.Thread(target=self._timeout_worker, daemon=True)
            self.timeout_thread.start()
        
        logger.info("AIå¯¹è¯æ¨¡å¼å·²å¯åŠ¨")
        
        # æ˜¾ç¤ºå¯åŠ¨çŠ¶æ€ - ç”¨è¡¨æƒ…ä»£æ›¿æ–‡å­—
        if self.display_controller:
            self.display_controller.show_emotion("happy", 30.0)
        
        # æ’­æ”¾å¯åŠ¨æç¤ºéŸ³å¹¶æä¾›å³æ—¶éŸ³é¢‘ç¡®è®¤
        self.speak_text("ä½ å¥½ï¼æˆ‘æ˜¯å¿«å¿«ï¼Œè¯´'å¿«å¿«'æ¥å”¤é†’æˆ‘å§~")
        
        return True
    
    def stop_conversation_mode(self):
        """åœæ­¢AIå¯¹è¯æ¨¡å¼"""
        self.conversation_mode = False
        self.wake_word_detected = False
        
        # åœæ­¢å”¤é†’è¯æ£€æµ‹
        if self.wake_word_detector and self.wake_word_active:
            self.wake_word_detector.stop_detection()
            self.wake_word_active = False
        
        if self.ai_conversation_manager:
            self.ai_conversation_manager.stop_conversation_mode()
        
        # æ¸…ç©ºé˜Ÿåˆ—
        self.clear_queues()
        
        logger.info("AIå¯¹è¯æ¨¡å¼å·²åœæ­¢")
        
        # æ˜¾ç¤ºåœæ­¢çŠ¶æ€ - ç”¨è¡¨æƒ…ä»£æ›¿æ–‡å­—
        if self.display_controller:
            self.display_controller.show_emotion("sleeping", 30.0)
        
        # æ’­æ”¾åœæ­¢æç¤ºéŸ³
        self.speak_text("å¯¹è¯æ¨¡å¼å·²å…³é—­ï¼Œå†è§~")
        
        # åœæ­¢æ˜¾ç¤ºæŽ§åˆ¶å™¨
        if self.display_controller:
            self.display_controller.stop()
    
    def _on_wake_word_detected(self, keyword_index):
        """å”¤é†’è¯æ£€æµ‹å›žè°ƒ - ä¿®å¤ç‰ˆæœ¬"""
        if not self.conversation_mode:
            return
            
        logger.info(f"ðŸŽ¤ æ£€æµ‹åˆ°å”¤é†’è¯ï¼ç´¢å¼•: {keyword_index}")
        logger.info("ðŸ¤– AIæ¡Œå® å·²å”¤é†’ï¼Œåœæ­¢å”¤é†’è¯æ£€æµ‹ï¼Œå¼€å§‹å¯¹è¯...")
        
        # å…³é”®ä¿®å¤ï¼šåœæ­¢å”¤é†’è¯æ£€æµ‹ï¼Œé¿å…éŸ³é¢‘æµå†²çª
        if self.wake_word_detector and self.wake_word_active:
            self.wake_word_detector.stop_detection()
            self.wake_word_active = False
            logger.info("ðŸ”‡ å·²åœæ­¢å”¤é†’è¯æ£€æµ‹")
        
        self.wake_word_detected = True
        self.last_interaction_time = time.time()
        
        # æ˜¾ç¤ºå”¤é†’çŠ¶æ€ - ç”¨è¡¨æƒ…ä»£æ›¿æ–‡å­—  
        if self.display_controller:
            self.display_controller.show_emotion("excited", 30.0)
        
        # æä¾›å³æ—¶éŸ³é¢‘ç¡®è®¤
        self.speak_text("æˆ‘åœ¨å¬ï¼Œè¯·è¯´~", priority=True)
        
        # å¦‚æžœæœ‰è¡¨æƒ…æŽ§åˆ¶å™¨ï¼Œæ˜¾ç¤ºè†å¬çŠ¶æ€
        if self.expression_controller:
            self.expression_controller.show_listening_animation()
    
    def _timeout_worker(self):
        """è¶…æ—¶æ£€æŸ¥å·¥ä½œçº¿ç¨‹"""
        while self.conversation_mode:
            try:
                current_time = time.time()
                if (self.wake_word_detected and 
                    current_time - self.last_interaction_time > self.conversation_timeout):
                    
                    logger.info("å¯¹è¯è¶…æ—¶ï¼Œè¿”å›žå¾…æœºæ¨¡å¼")
                    self.wake_word_detected = False
                    
                    # é‡å¯å”¤é†’è¯æ£€æµ‹ï¼ˆå…³é”®ä¿®å¤ï¼‰
                    if self.wake_word_detector and not self.wake_word_active:
                        if self.wake_word_detector.start_detection(self._on_wake_word_detected):
                            self.wake_word_active = True
                            logger.info("ðŸ”” å·²é‡å¯å”¤é†’è¯æ£€æµ‹")
                        else:
                            logger.warning("é‡å¯å”¤é†’è¯æ£€æµ‹å¤±è´¥")
                    
                    # å¦‚æžœæœ‰è¡¨æƒ…æŽ§åˆ¶å™¨ï¼Œæ˜¾ç¤ºç©ºé—²çŠ¶æ€
                    if self.expression_controller:
                        self.expression_controller.show_idle_animation()
                
                time.sleep(5)  # æ¯5ç§’æ£€æŸ¥ä¸€æ¬¡
                
            except Exception as e:
                logger.error(f"è¶…æ—¶æ£€æŸ¥é”™è¯¯: {e}")
                time.sleep(5)

    def _state_machine_worker(self):
        """çŠ¶æ€æœºå·¥ä½œçº¿ç¨‹ - ä¿®å¤éŸ³é¢‘æµå†²çª"""
        logger.info("çŠ¶æ€æœºçº¿ç¨‹å¯åŠ¨")
        
        while self.conversation_mode:
            try:
                if self.wake_word_detected:
                    # å¤„äºŽå¯¹è¯çŠ¶æ€ï¼Œè¿›è¡Œè¯­éŸ³è¯†åˆ«
                    self._handle_conversation_round()
                else:
                    # ç­‰å¾…å”¤é†’ï¼ŒçŸ­æš‚ä¼‘çœ 
                    time.sleep(0.5)
                    
            except Exception as e:
                logger.error(f"çŠ¶æ€æœºé”™è¯¯: {e}")
                time.sleep(1)
        
        logger.info("çŠ¶æ€æœºçº¿ç¨‹ç»“æŸ")
    
    def _safe_state_machine_worker(self):
        """å®‰å…¨çŠ¶æ€æœºå·¥ä½œçº¿ç¨‹ - æµ‹è¯•æ¨¡å¼ï¼Œä¸ä½¿ç”¨éŸ³é¢‘æµ"""
        logger.info("å®‰å…¨çŠ¶æ€æœºçº¿ç¨‹å¯åŠ¨ï¼ˆæµ‹è¯•æ¨¡å¼ï¼‰")
        
        while self.conversation_mode:
            try:
                # æµ‹è¯•æ¨¡å¼ä¸‹åªåšçŠ¶æ€ç®¡ç†ï¼Œä¸è¿›è¡Œå®žé™…éŸ³é¢‘æ“ä½œ
                if self.wake_word_detected:
                    logger.info("ðŸŽ™ï¸ æ¨¡æ‹Ÿå¯¹è¯çŠ¶æ€ï¼ˆæµ‹è¯•æ¨¡å¼ï¼‰")
                    # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
                    time.sleep(2)
                    # å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ æ¨¡æ‹Ÿçš„AIå¯¹è¯å¤„ç†
                else:
                    # ç­‰å¾…çŠ¶æ€
                    time.sleep(1)
                    
            except Exception as e:
                logger.error(f"å®‰å…¨çŠ¶æ€æœºé”™è¯¯: {e}")
                time.sleep(1)
        
        logger.info("å®‰å…¨çŠ¶æ€æœºçº¿ç¨‹ç»“æŸ")
    
    def _handle_conversation_round(self):
        """å¤„ç†ä¸€è½®å¯¹è¯"""
        try:
            # æ£€æŸ¥æ˜¯å¦æ­£åœ¨æ’­æ”¾éŸ³é¢‘ï¼Œé¿å…å½•åˆ¶å›žéŸ³
            if self.is_playing_audio or self.recording_paused:
                logger.debug("ðŸ”‡ è·³è¿‡å½•éŸ³ï¼ˆæ­£åœ¨æ’­æ”¾æˆ–å·²æš‚åœï¼‰")
                time.sleep(0.5)  # çŸ­æš‚ç­‰å¾…
                return
            
            logger.info("ðŸŽ™ï¸ ç­‰å¾…ç”¨æˆ·è¯´è¯...")
            
            # å½•éŸ³ï¼ˆæ­¤æ—¶å”¤é†’è¯æ£€æµ‹å·²åœæ­¢ï¼Œåªæœ‰è¿™ä¸€ä¸ªéŸ³é¢‘æµï¼‰
            recognizer = sr.Recognizer()
            microphone = sr.Microphone()
            
            with microphone as source:
                # å†æ¬¡æ£€æŸ¥æ’­æ”¾çŠ¶æ€ï¼ˆé˜²æ­¢å½•éŸ³è¿‡ç¨‹ä¸­å¼€å§‹æ’­æ”¾ï¼‰
                if self.is_playing_audio or self.recording_paused:
                    logger.debug("ðŸ”‡ å½•éŸ³è¿‡ç¨‹ä¸­æ£€æµ‹åˆ°æ’­æ”¾ï¼Œè·³è¿‡")
                    return
                
                recognizer.adjust_for_ambient_noise(source, duration=0.5)
                audio = recognizer.listen(source, timeout=8, phrase_time_limit=10)
            
            # æœ€åŽæ£€æŸ¥ï¼šé¿å…å¤„ç†å¯èƒ½çš„å›žéŸ³éŸ³é¢‘
            if self.is_playing_audio or self.recording_paused:
                logger.debug("ðŸ”‡ è·³è¿‡å¯èƒ½çš„å›žéŸ³éŸ³é¢‘å¤„ç†")
                return
            
            # è¯­éŸ³è¯†åˆ«
            text = self._recognize_speech_enhanced(audio)
            if not text or not text.strip():
                logger.info("æœªè¯†åˆ«åˆ°æœ‰æ•ˆè¯­éŸ³")
                return
            
            logger.info(f"ðŸ“ ç”¨æˆ·è¯´: {text}")
            self.last_interaction_time = time.time()
            
            # æ˜¾ç¤ºç”¨æˆ·è¯­éŸ³çŠ¶æ€ - ç”¨è¡¨æƒ…ä»£æ›¿æ–‡å­—
            if self.display_controller:
                self.display_controller.show_emotion("thinking", 30.0)
            
            # AIå¤„ç†
            self._process_conversation_text(text)
            
        except sr.WaitTimeoutError:
            logger.info("å½•éŸ³è¶…æ—¶ï¼Œç»§ç»­ç­‰å¾…")
        except Exception as e:
            logger.error(f"å¯¹è¯è½®æ¬¡é”™è¯¯: {e}")
    
    def _recognize_speech_enhanced(self, audio):
        """å¢žå¼ºçš„è¯­éŸ³è¯†åˆ«ï¼ˆå¸¦å›žéŸ³æ£€æµ‹ï¼‰"""
        # æ£€æŸ¥æ˜¯å¦æ­£åœ¨æ’­æ”¾ï¼Œé¿å…è¯†åˆ«å›žéŸ³
        if self.is_playing_audio or self.recording_paused:
            logger.debug("ðŸ”‡ è·³è¿‡è¯­éŸ³è¯†åˆ«ï¼ˆæ­£åœ¨æ’­æ”¾éŸ³é¢‘ï¼‰")
            return ""
        
        # 1. ä¼˜å…ˆä½¿ç”¨ä¿®å¤åŽçš„Voskä¸­æ–‡è¯†åˆ«
        if self.use_vosk and self.vosk_recognizer:
            try:
                result = self.vosk_recognizer.recognize_from_speech_recognition_audio(audio)
                if result and result.strip():
                    logger.info(f"âœ… Voskè¯†åˆ«æˆåŠŸ: {result}")
                    return result
            except Exception as e:
                logger.error(f"Voskè¯†åˆ«å¤±è´¥: {e}")
        
        # 2. å¤‡é€‰ï¼šGoogleåœ¨çº¿è¯†åˆ«
        try:
            recognizer = sr.Recognizer()
            result = recognizer.recognize_google(audio, language='zh-CN')
            if result and result.strip():
                logger.info(f"âœ… Googleè¯†åˆ«æˆåŠŸ: {result}")
                return result
        except Exception as e:
            logger.error(f"Googleè¯†åˆ«å¤±è´¥: {e}")
        
        return None
    
    def _process_conversation_text(self, text):
        """å¤„ç†å¯¹è¯æ–‡æœ¬"""
        try:
            # æ˜¾ç¤ºæ€è€ƒçŠ¶æ€ - ç”¨è¡¨æƒ…ä»£æ›¿æ–‡å­—
            if self.display_controller:
                self.display_controller.show_emotion("thinking", 30.0)
            if self.expression_controller:
                self.expression_controller.show_thinking_animation()
            
            # AIå¤„ç†
            context = self.ai_conversation_manager.process_user_input(text)
            
            if context and context.ai_response:
                logger.info(f"ðŸ¤– AIå›žå¤: {context.ai_response}")
                
                # æ˜¾ç¤ºæƒ…æ„Ÿè¡¨æƒ… - åªæ˜¾ç¤ºè¡¨æƒ…ï¼Œä¸æ˜¾ç¤ºæ–‡å­—
                if context.emotion_detected:
                    logger.info(f"ðŸ˜Š æ£€æµ‹æƒ…æ„Ÿ: {context.emotion_detected}")
                    if self.display_controller:
                        self.display_controller.show_emotion(context.emotion_detected, 30.0)
                else:
                    # å¦‚æžœæ²¡æœ‰æ£€æµ‹åˆ°æƒ…æ„Ÿï¼Œæ˜¾ç¤ºå¼€å¿ƒè¡¨æƒ…
                    if self.display_controller:
                        self.display_controller.show_emotion("happy", 30.0)
                
                # è¯­éŸ³è¾“å‡º
                self.speak_text(context.ai_response)
                
                # æ›´æ–°äº¤äº’æ—¶é—´
                self.last_interaction_time = time.time()
            else:
                logger.warning("AIå¤„ç†å¤±è´¥")
                if self.display_controller:
                    self.display_controller.show_emotion("confused", 30.0)
                self.speak_text("æŠ±æ­‰ï¼Œæˆ‘æ²¡å¬æ¸…æ¥šï¼Œèƒ½å†è¯´ä¸€éå—ï¼Ÿ")
                
        except Exception as e:
            logger.error(f"å¯¹è¯å¤„ç†é”™è¯¯: {e}")

    def listen_continuously(self):
        """æŒç»­ç›‘å¬è¯­éŸ³å‘½ä»¤å’Œå¯¹è¯"""
        if not self.microphone:
            logger.error("éº¦å…‹é£Žæœªåˆå§‹åŒ–ï¼Œæ— æ³•å¼€å§‹è¯­éŸ³è¯†åˆ«")
            return
            
        self.is_listening = True
        logger.info("å¼€å§‹è¯­éŸ³è¯†åˆ«ç›‘å¬...")
        
        # ä¼˜åŒ–è¯†åˆ«å™¨å‚æ•°ä»¥æé«˜å‡†ç¡®æ€§
        self.recognizer.energy_threshold = 4000  # æé«˜èƒ½é‡é˜ˆå€¼ï¼Œå‡å°‘å™ªéŸ³å¹²æ‰°
        self.recognizer.pause_threshold = 1.0    # å¢žåŠ åœé¡¿æ—¶é—´ï¼Œç¡®ä¿å®Œæ•´å¥å­
        self.recognizer.timeout = 2              # å¢žåŠ è¶…æ—¶æ—¶é—´
        self.recognizer.phrase_time_limit = 10   # å…è®¸æ›´é•¿çš„è¯­éŸ³è¾“å…¥
        
        while self.is_listening:
            try:
                # åªæœ‰åœ¨å”¤é†’çŠ¶æ€ä¸‹æ‰è¿›è¡Œè¯­éŸ³è¯†åˆ«
                if self.conversation_mode and self.wake_word_detected:
                    # æ£€æŸ¥æ˜¯å¦æ­£åœ¨æ’­æ”¾éŸ³é¢‘ï¼Œé¿å…å½•åˆ¶å›žéŸ³
                    if self.is_playing_audio or self.recording_paused:
                        logger.debug("ðŸ”‡ è·³è¿‡å½•éŸ³ï¼ˆæ­£åœ¨æ’­æ”¾æˆ–å·²æš‚åœï¼‰")
                        time.sleep(0.5)  # çŸ­æš‚ç­‰å¾…
                        continue
                    
                    with self.microphone as source:
                        logger.debug("æ­£åœ¨ç›‘å¬å¯¹è¯...")
                        # å†æ¬¡æ£€æŸ¥æ’­æ”¾çŠ¶æ€ï¼ˆé˜²æ­¢å½•éŸ³è¿‡ç¨‹ä¸­å¼€å§‹æ’­æ”¾ï¼‰
                        if self.is_playing_audio or self.recording_paused:
                            logger.debug("ðŸ”‡ å½•éŸ³è¿‡ç¨‹ä¸­æ£€æµ‹åˆ°æ’­æ”¾ï¼Œè·³è¿‡")
                            continue
                        
                        # å¯¹è¯æ¨¡å¼ä¸‹ä¼˜åŒ–éŸ³é¢‘æ•èŽ·
                        self.recognizer.adjust_for_ambient_noise(source, duration=0.5)
                        audio = self.recognizer.listen(source, timeout=3, phrase_time_limit=10)
                    
                    # æœ€åŽæ£€æŸ¥ï¼šé¿å…å¤„ç†å¯èƒ½çš„å›žéŸ³éŸ³é¢‘
                    if self.is_playing_audio or self.recording_paused:
                        logger.debug("ðŸ”‡ è·³è¿‡å¯èƒ½çš„å›žéŸ³éŸ³é¢‘å¤„ç†")
                        continue
                    
                    # å°†éŸ³é¢‘æ”¾å…¥å¤„ç†é˜Ÿåˆ—
                    self.audio_queue.put(audio)
                else:
                    # éžå¯¹è¯æ¨¡å¼æˆ–æœªå”¤é†’æ—¶ï¼ŒçŸ­æš‚ä¼‘çœ 
                    time.sleep(0.1)
                
            except sr.WaitTimeoutError:
                # è¶…æ—¶æ˜¯æ­£å¸¸çš„ï¼Œç»§ç»­ç›‘å¬
                pass
            except Exception as e:
                logger.error(f"ç›‘å¬é”™è¯¯: {e}")
                time.sleep(1)
    
    def _conversation_worker(self):
        """å¯¹è¯å¤„ç†å·¥ä½œçº¿ç¨‹"""
        while self.conversation_mode:
            try:
                # ä»Žé˜Ÿåˆ—èŽ·å–éŸ³é¢‘
                audio = self.audio_queue.get(timeout=1)
                
                # å¤„ç†éŸ³é¢‘
                if self.conversation_mode and self.wake_word_detected:
                    self._process_conversation_audio(audio)
                elif not self.conversation_mode:
                    # ä¼ ç»Ÿå‘½ä»¤æ¨¡å¼
                    self._process_audio(audio)
                
                self.audio_queue.task_done()
                
            except queue.Empty:
                continue
            except Exception as e:
                logger.error(f"å¯¹è¯å¤„ç†é”™è¯¯: {e}")
    
    def _process_conversation_audio(self, audio):
        """å¤„ç†å¯¹è¯æ¨¡å¼ä¸‹çš„éŸ³é¢‘"""
        try:
            logger.info("ðŸŽ™ï¸ å¼€å§‹å¤„ç†å½•éŸ³éŸ³é¢‘...")
            # æ˜¾ç¤ºæ€è€ƒçŠ¶æ€
            if self.expression_controller:
                self.expression_controller.show_thinking_animation()
            
            # è¯­éŸ³è¯†åˆ« - ä¼˜åŒ–é¡ºåºï¼šGoogle(åœ¨çº¿) > Vosk(ä¸­æ–‡) > Whisper > PocketSphinx(è‹±æ–‡)
            text = None
            logger.info("ðŸ” å¼€å§‹è¯­éŸ³è¯†åˆ«ï¼Œå°è¯•é¡ºåº: Google â†’ Vosk â†’ Whisper â†’ PocketSphinx")
            
            # 1. ä¼˜å…ˆä½¿ç”¨Googleåœ¨çº¿è¯†åˆ«ï¼ˆå‡†ç¡®æ€§æœ€é«˜ï¼‰
            try:
                logger.info("ðŸŽ¯ å°è¯•ä½¿ç”¨Googleåœ¨çº¿è¯†åˆ«...")
                text = self.recognizer.recognize_google(audio, language='zh-CN')
                if text and text.strip():
                    logger.info(f"âœ… Googleè¯†åˆ«æˆåŠŸ: '{text}' (ä¸­æ–‡åœ¨çº¿)")
                else:
                    logger.info("âš ï¸  Googleè¿”å›žç©ºç»“æžœ")
                    text = None
            except sr.UnknownValueError:
                logger.info("âš ï¸  Googleæ— æ³•ç†è§£éŸ³é¢‘")
                text = None
            except sr.RequestError as e:
                logger.warning(f"âŒ GoogleæœåŠ¡é”™è¯¯: {e}")
                text = None
            except Exception as e:
                logger.warning(f"âŒ Googleè¯†åˆ«å¤±è´¥: {e}")
                text = None
            
            # 2. å¤‡é€‰ï¼šä½¿ç”¨Voskè¿›è¡Œä¸­æ–‡è¯†åˆ«
            if not text and self.use_vosk and self.vosk_recognizer:
                logger.info("ðŸŽ¯ å°è¯•ä½¿ç”¨Voskè¿›è¡Œä¸­æ–‡è¯†åˆ«...")
                try:
                    text = self.vosk_recognizer.recognize_from_speech_recognition_audio(audio)
                    if text and text.strip():
                        logger.info(f"âœ… Voskè¯†åˆ«æˆåŠŸ: '{text}' (ä¸­æ–‡ç¦»çº¿)")
                    else:
                        logger.info("âš ï¸  Voskè¿”å›žç©ºç»“æžœ")
                        text = None
                except Exception as e:
                    logger.warning(f"âŒ Voskè¯†åˆ«å¤±è´¥: {e}")
                    text = None
            
            # 3. å¤‡é€‰ï¼šä½¿ç”¨Whisper
            if not text and self.use_whisper and self.whisper_recognizer:
                logger.info("ðŸŽ¯ å°è¯•ä½¿ç”¨Whisperè¯†åˆ«...")
                try:
                    text = self._whisper_recognize_from_audio(audio)
                    if text and text.strip():
                        logger.info(f"âœ… Whisperè¯†åˆ«æˆåŠŸ: '{text}' (å¤šè¯­è¨€ç¦»çº¿)")
                    else:
                        logger.info("âš ï¸  Whisperè¿”å›žç©ºç»“æžœ")
                        text = None
                except Exception as e:
                    logger.warning(f"âŒ Whisperè¯†åˆ«å¤±è´¥: {e}")
                    text = None
            
            # 4. æœ€åŽå¤‡é€‰ï¼šä½¿ç”¨PocketSphinxï¼ˆè‹±æ–‡ï¼‰
            if not text:
                logger.info("ðŸŽ¯ å°è¯•ä½¿ç”¨PocketSphinxè¯†åˆ«...")
                try:
                    sphinx_text = self.recognizer.recognize_sphinx(audio)
                    if sphinx_text and sphinx_text.strip():
                        text = sphinx_text
                        logger.info(f"âœ… PocketSphinxè¯†åˆ«æˆåŠŸ: '{text}' (è‹±æ–‡ç¦»çº¿)")
                    else:
                        logger.info("âš ï¸  PocketSphinxè¿”å›žç©ºç»“æžœ")
                except Exception as e:
                    logger.warning(f"âŒ PocketSphinxè¯†åˆ«å¤±è´¥: {e}")
            
            if not text or not text.strip():
                logger.warning("âŒ æ‰€æœ‰è¯­éŸ³è¯†åˆ«å¼•æ“Žéƒ½æœªèƒ½è¯†åˆ«åˆ°æœ‰æ•ˆå†…å®¹")
                logger.info("ðŸ’¡ å»ºè®®: 1)è¯´è¯å£°éŸ³å¤§ä¸€äº› 2)é è¿‘éº¦å…‹é£Ž 3)åœ¨å®‰é™çŽ¯å¢ƒä¸­è¯´è¯")
                
                # æ’­æ”¾è¯†åˆ«å¤±è´¥æç¤º
                self.speak_text("æŠ±æ­‰ï¼Œæˆ‘æ²¡æœ‰å¬æ¸…æ¥šï¼Œè¯·å†è¯´ä¸€é~")
                return
                
            text = text.strip()
            logger.info(f"ðŸŽ¯ æœ€ç»ˆè¯†åˆ«ç»“æžœ: '{text}'")
            
            # æ›´æ–°äº¤äº’æ—¶é—´
            self.last_interaction_time = time.time()
            
            # æ˜¾ç¤ºè¯†åˆ«æˆåŠŸçš„åé¦ˆ
            if self.expression_controller:
                self.expression_controller.show_processing_animation()
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯ç»“æŸå¯¹è¯çš„å‘½ä»¤
            if any(word in text for word in ['å†è§', 'ç»“æŸå¯¹è¯', 'åœæ­¢', 'é€€å‡º', 'ç¡è§‰']):
                self.wake_word_detected = False
                self.speak_text("å¥½çš„ï¼Œæœ‰éœ€è¦å†å«æˆ‘~")
                
                if self.expression_controller:
                    self.expression_controller.show_idle_animation()
                return
            
            # å‘é€åˆ°AIå¯¹è¯ç®¡ç†å™¨
            context = self.ai_conversation_manager.process_user_input(text)
            
            if context and context.ai_response:
                # æ’­æ”¾AIå›žå¤
                self.speak_text(context.ai_response)
                
                # æ ¹æ®æƒ…æ„Ÿæ‰§è¡Œç›¸åº”åŠ¨ä½œ
                self._execute_emotional_action(context.emotion_detected)
            else:
                # å¤„ç†å¤±è´¥æ—¶çš„åé¦ˆ
                self.speak_text("æŠ±æ­‰ï¼Œæˆ‘æ²¡æœ‰ç†è§£ï¼Œè¯·å†è¯´ä¸€é~")
            
        except sr.UnknownValueError:
            logger.debug("æ— æ³•ç†è§£éŸ³é¢‘")
        except sr.RequestError as e:
            logger.error(f"è¯­éŸ³è¯†åˆ«æœåŠ¡é”™è¯¯: {e}")
            self.speak_text("è¯­éŸ³è¯†åˆ«å‡ºçŽ°é—®é¢˜ï¼Œè¯·ç¨åŽå†è¯•~")
        except Exception as e:
            logger.error(f"å¯¹è¯éŸ³é¢‘å¤„ç†é”™è¯¯: {e}")
            self.speak_text("å¤„ç†å‡ºçŽ°é—®é¢˜ï¼Œè¯·ç¨åŽå†è¯•~")
    
    def _whisper_recognize_from_audio(self, audio):
        """ä½¿ç”¨Whisperè¿›è¡Œè¯­éŸ³è¯†åˆ«"""
        try:
            if not self.whisper_recognizer:
                return None
                
            # å°†SpeechRecognitionçš„AudioDataè½¬æ¢ä¸ºéŸ³é¢‘æ•°æ®
            wav_data = audio.get_wav_data()
            
            # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
            with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as temp_file:
                temp_file.write(wav_data)
                temp_file_path = temp_file.name
            
            try:
                # ä½¿ç”¨Whisperè¯†åˆ«
                text = self.whisper_recognizer.recognize_audio_file(temp_file_path)
                return text
            finally:
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                if os.path.exists(temp_file_path):
                    os.unlink(temp_file_path)
            
        except Exception as e:
            logger.error(f"Whisperè¯†åˆ«å¤±è´¥: {e}")
            return None
    
    def _execute_emotional_action(self, emotion):
        """æ ¹æ®æƒ…æ„Ÿæ‰§è¡Œç›¸åº”çš„æœºå™¨äººåŠ¨ä½œ"""
        if not self.robot:
            return
            
        try:
            if emotion == 'happy':
                # å¼€å¿ƒæ—¶è½¬ä¸ªåœˆ
                self.robot.turnRight(30, 0.5)
                self.robot.turnLeft(30, 0.5)
                
            elif emotion == 'excited':
                # å…´å¥‹æ—¶å¿«é€Ÿå·¦å³æ‘†åŠ¨
                self.robot.turnLeft(40, 0.2)
                self.robot.turnRight(40, 0.2)
                self.robot.turnLeft(40, 0.2)
                
            elif emotion == 'sad':
                # æ‚²ä¼¤æ—¶ç¼“æ…¢åŽé€€
                self.robot.t_down(20, 0.5)
                
            elif emotion == 'confused':
                # å›°æƒ‘æ—¶å·¦å³æ‘‡å¤´
                self.robot.turnLeft(25, 0.3)
                self.robot.turnRight(25, 0.3)
                
            elif emotion == 'thinking':
                # æ€è€ƒæ—¶è½»å¾®æ‘†åŠ¨
                self.robot.moveLeft(15, 0.2)
                self.robot.moveRight(15, 0.2)
                
        except Exception as e:
            logger.error(f"æ‰§è¡Œæƒ…æ„ŸåŠ¨ä½œå¤±è´¥: {e}")
    
    def _filter_tts_text(self, text):
        """è¿‡æ»¤TTSæ–‡æœ¬ï¼Œç§»é™¤æ‹¬å·ä¸­çš„è¡¨æƒ…å’ŒåŠ¨ä½œæè¿°"""
        if not text:
            return text
        
        # ç§»é™¤å„ç§ç±»åž‹çš„æ‹¬å·å†…å®¹
        # åŒ¹é…åœ†æ‹¬å·å†…å®¹ï¼š(è¡¨æƒ…æè¿°)
        text = re.sub(r'\([^)]*\)', '', text)
        # åŒ¹é…æ–¹æ‹¬å·å†…å®¹ï¼š[åŠ¨ä½œæè¿°]
        text = re.sub(r'\[[^\]]*\]', '', text)
        # åŒ¹é…ä¸­æ–‡åœ†æ‹¬å·ï¼šï¼ˆè¡¨æƒ…ï¼‰
        text = re.sub(r'ï¼ˆ[^ï¼‰]*ï¼‰', '', text)
        # åŒ¹é…ä¸­æ–‡æ–¹æ‹¬å·ï¼šã€åŠ¨ä½œã€‘
        text = re.sub(r'ã€[^ã€‘]*ã€‘', '', text)
        
        # æ¸…ç†å¤šä½™çš„ç©ºç™½å­—ç¬¦
        text = re.sub(r'\s+', ' ', text).strip()
        
        return text
    
    def speak_text(self, text, priority=False):
        """å°†æ–‡æœ¬è½¬æ¢ä¸ºè¯­éŸ³å¹¶æ’­æ”¾"""
        if text:
            # è¿‡æ»¤æŽ‰æ‹¬å·ä¸­çš„è¡¨æƒ…å’ŒåŠ¨ä½œæè¿°
            filtered_text = self._filter_tts_text(text)
            
            if filtered_text:  # ç¡®ä¿è¿‡æ»¤åŽè¿˜æœ‰å†…å®¹
                if priority:
                    # ä¼˜å…ˆçº§é«˜çš„æ¶ˆæ¯æ’å…¥é˜Ÿåˆ—å‰ç«¯
                    temp_queue = queue.Queue()
                    temp_queue.put(filtered_text)
                    while not self.tts_queue.empty():
                        temp_queue.put(self.tts_queue.get())
                    self.tts_queue = temp_queue
                else:
                    self.tts_queue.put(filtered_text)
    
    def _tts_worker(self):
        """TTSå¤„ç†å·¥ä½œçº¿ç¨‹"""
        while self.conversation_mode or not self.tts_queue.empty():
            try:
                # ä»Žé˜Ÿåˆ—èŽ·å–æ–‡æœ¬
                text = self.tts_queue.get(timeout=1)
                
                # æ˜¾ç¤ºè¯´è¯åŠ¨ç”»
                if self.expression_controller:
                    # ä¼°ç®—è¯´è¯æ—¶é•¿
                    estimated_duration = len(text) * 0.15  # å¤§çº¦æ¯ä¸ªå­—0.15ç§’
                    threading.Thread(
                        target=self.expression_controller.animate_speaking,
                        args=(estimated_duration,),
                        daemon=True
                    ).start()
                
                # ä½¿ç”¨edge-ttsç”Ÿæˆè¯­éŸ³
                self._generate_and_play_speech(text)
                
                self.tts_queue.task_done()
                
            except queue.Empty:
                continue
            except Exception as e:
                logger.error(f"TTSå¤„ç†é”™è¯¯: {e}")
    
    def _pause_recording(self):
        """æš‚åœå½•éŸ³ä»¥é˜²å›žéŸ³"""
        with self.audio_lock:
            if not self.recording_paused:
                logger.debug("ðŸ”‡ æš‚åœå½•éŸ³ï¼ˆé˜²å›žéŸ³ï¼‰")
                self.recording_paused = True
                # å¦‚æžœæœ‰æ´»è·ƒçš„è¯†åˆ«æµï¼Œæš‚åœå®ƒä»¬
                if hasattr(self, 'vosk_recognizer') and self.vosk_recognizer:
                    # Voskè¯†åˆ«å™¨ä¸éœ€è¦ç‰¹æ®Šæš‚åœï¼Œå®ƒæ˜¯åŸºäºŽæ•°æ®æµçš„
                    pass
    
    def _resume_recording(self):
        """æ¢å¤å½•éŸ³"""
        with self.audio_lock:
            if self.recording_paused:
                logger.debug("ðŸŽ¤ æ¢å¤å½•éŸ³")
                self.recording_paused = False
                # æ¢å¤è¯†åˆ«æµ
                if hasattr(self, 'vosk_recognizer') and self.vosk_recognizer:
                    pass
    
    def _generate_and_play_speech(self, text):
        """ç”Ÿæˆå¹¶æ’­æ”¾è¯­éŸ³ï¼ˆå¸¦å›žéŸ³é˜²æŠ¤ï¼‰"""
        try:
            # æ£€æŸ¥æ˜¯å¦åœ¨ç¦»çº¿æ¨¡å¼
            if self.safety_manager and self.safety_manager.safety_state.offline_mode_active:
                logger.info(f"ç¦»çº¿æ¨¡å¼TTS: {text}")
                return
            
            # è®¾ç½®æ’­æ”¾çŠ¶æ€å¹¶æš‚åœå½•éŸ³
            with self.audio_lock:
                self.is_playing_audio = True
            self._pause_recording()
            
            try:
                # åˆ›å»ºä¸´æ—¶MP3æ–‡ä»¶
                with tempfile.NamedTemporaryFile(suffix='.mp3', delete=False) as temp_file:
                    mp3_file_path = temp_file.name
                
                # ä½¿ç”¨edge-ttsç”ŸæˆMP3è¯­éŸ³
                asyncio.run(self._async_generate_speech(text, mp3_file_path))
                
                # æ’­æ”¾éŸ³é¢‘æ–‡ä»¶
                self._play_audio_file_pygame(mp3_file_path)
                
                # æ’­æ”¾å®ŒæˆåŽç­‰å¾…ä¸€å°æ®µæ—¶é—´
                time.sleep(0.5)  # ç­‰å¾…éŸ³é¢‘å®Œå…¨æ’­æ”¾å®Œæˆ
                
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                if os.path.exists(mp3_file_path):
                    os.unlink(mp3_file_path)
                    
            finally:
                # æ¢å¤å½•éŸ³çŠ¶æ€
                with self.audio_lock:
                    self.is_playing_audio = False
                self._resume_recording()
                logger.debug("ðŸ”Š éŸ³é¢‘æ’­æ”¾å®Œæˆï¼Œå·²æ¢å¤å½•éŸ³")
            
        except Exception as e:
            logger.error(f"è¯­éŸ³ç”Ÿæˆæ’­æ”¾å¤±è´¥: {e}")
            
            # ç¡®ä¿åœ¨å¼‚å¸¸æƒ…å†µä¸‹ä¹Ÿæ¢å¤å½•éŸ³
            with self.audio_lock:
                self.is_playing_audio = False
            self._resume_recording()
            
            # è®°å½•TTSå¤±è´¥
            if self.safety_manager:
                self.safety_manager.handle_api_failure("tts_error", 0)
    
    async def _async_generate_speech(self, text, output_path):
        """å¼‚æ­¥ç”Ÿæˆè¯­éŸ³ - Azure TTSä¸ºä¸»ï¼Œedge-ttsä¸ºå¤‡é€‰"""
        # ä¼˜å…ˆä½¿ç”¨Azure TTS
        if self.azure_tts:
            try:
                logger.debug("å°è¯•ä½¿ç”¨Azure TTSç”Ÿæˆè¯­éŸ³")
                success = self.azure_tts.synthesize_to_file(text, output_path)
                if success:
                    logger.debug("Azure TTSç”ŸæˆæˆåŠŸ")
                    return True
                else:
                    logger.warning("Azure TTSç”Ÿæˆå¤±è´¥")
            except Exception as azure_e:
                logger.warning(f"Azure TTSå¼‚å¸¸: {azure_e}")
        else:
            logger.debug("Azure TTSæœªé…ç½®")
        
        # å¤‡é€‰æ–¹æ¡ˆï¼šä½¿ç”¨edge-tts
        try:
            logger.info("å°è¯•ä½¿ç”¨edge-ttså¤‡é€‰æ–¹æ¡ˆ")
            communicate = edge_tts.Communicate(text, self.tts_voice)
            await communicate.save(output_path)
            logger.info("edge-ttsç”ŸæˆæˆåŠŸ")
            return True
        except Exception as e:
            logger.error(f"edge-ttsè¯­éŸ³ç”Ÿæˆå¤±è´¥: {e}")
            
            # ä¸¤ç§TTSéƒ½å¤±è´¥
            logger.error("æ‰€æœ‰TTSæ–¹æ¡ˆéƒ½å¤±è´¥")
            raise Exception(f"TTSç”Ÿæˆå¤±è´¥: Azure TTSä¸å¯ç”¨æˆ–å¤±è´¥, edge-ttsé”™è¯¯={e}")
    
    def _play_audio_file_pygame(self, file_path):
        """ä½¿ç”¨å¯é çš„éŸ³é¢‘æ’­æ”¾æ–¹å¼"""
        try:
            # ä¼˜å…ˆä½¿ç”¨æˆ‘ä»¬ä¿®å¤çš„å¯é æ’­æ”¾æ–¹å¼
            self._play_audio_file_reliable(file_path)
        except Exception as e:
            logger.error(f"å¯é æ’­æ”¾å¤±è´¥: {e}")
            # å¤‡é€‰æ–¹æ¡ˆ
            self._play_audio_file_system(file_path)
    
    def _play_audio_file_reliable(self, file_path):
        """ä½¿ç”¨ä¿®å¤åŽçš„å¯é æ’­æ”¾æ–¹å¼"""
        try:
            # å¦‚æžœæ˜¯MP3æ–‡ä»¶ï¼Œéœ€è¦è½¬æ¢ä¸ºWAV
            if file_path.endswith('.mp3'):
                wav_path = file_path.replace('.mp3', '.wav')
                
                # ä½¿ç”¨ffmpegè½¬æ¢ï¼ˆå®Œæ•´è·¯å¾„ï¼‰
                convert_cmd = [
                    '/usr/bin/ffmpeg', '-i', file_path,
                    '-ar', '44100',  # é‡‡æ ·çŽ‡44100Hz
                    '-ac', '1',      # å•å£°é“
                    '-f', 'wav',     # WAVæ ¼å¼
                    '-y',            # è¦†ç›–è¾“å‡ºæ–‡ä»¶
                    wav_path
                ]
                
                result = subprocess.run(convert_cmd, capture_output=True, text=True)
                if result.returncode == 0:
                    file_path = wav_path
                else:
                    logger.warning(f"éŸ³é¢‘è½¬æ¢å¤±è´¥ï¼Œå°è¯•ç›´æŽ¥æ’­æ”¾: {result.stderr}")
            
            # ä½¿ç”¨ä¿®å¤åŽçš„å¯é æ’­æ”¾å‘½ä»¤
            result = subprocess.run(['/usr/bin/aplay', '-D', 'hw:0,0', file_path], 
                                  capture_output=True, text=True, timeout=60)
            
            if result.returncode == 0:
                logger.debug("éŸ³é¢‘æ’­æ”¾æˆåŠŸ")
                # æ¸…ç†è½¬æ¢çš„WAVæ–‡ä»¶
                if file_path.endswith('.wav') and file_path != file_path.replace('.mp3', '.wav'):
                    try:
                        os.unlink(file_path)
                    except:
                        pass
                return
            else:
                logger.error(f"éŸ³é¢‘æ’­æ”¾å¤±è´¥: {result.stderr}")
                raise Exception(f"aplay failed: {result.stderr}")
                
        except Exception as e:
            logger.error(f"å¯é æ’­æ”¾æ–¹å¼å¤±è´¥: {e}")
            raise
    
    def _play_audio_file_system(self, file_path):
        """ä½¿ç”¨ç³»ç»Ÿå‘½ä»¤æ’­æ”¾éŸ³é¢‘æ–‡ä»¶ï¼ˆå¤‡é€‰æ–¹æ¡ˆï¼‰"""
        try:
            # å¤‡é€‰ï¼šä½¿ç”¨mpg123
            subprocess.run(['mpg123', file_path], 
                         check=True, 
                         capture_output=True,
                         timeout=10)
        except:
            try:
                # å¤‡é€‰ï¼šä½¿ç”¨ffplay
                subprocess.run(['ffplay', '-nodisp', '-autoexit', file_path], 
                             check=True, 
                             capture_output=True,
                             timeout=10)
            except:
                logger.error("æ— æ³•æ’­æ”¾éŸ³é¢‘æ–‡ä»¶ï¼Œè¯·å®‰è£…aplayã€mpg123æˆ–ffplay")
    
    def get_conversation_status(self):
        """èŽ·å–å¯¹è¯çŠ¶æ€"""
        # ç¡®å®šå½“å‰çŠ¶æ€
        if not self.conversation_mode:
            current_state = "stopped"
        elif self.wake_word_detected:
            current_state = "conversation"
        else:
            current_state = "waiting"
            
        return {
            'conversation_mode': self.conversation_mode,
            'state': current_state,
            'wake_word_detected': self.wake_word_detected,
            'wake_word_active': self.wake_word_active,
            'ai_manager_active': self.ai_conversation_manager.is_active() if self.ai_conversation_manager else False,
            'tts_queue_size': self.tts_queue.qsize(),
            'audio_queue_size': self.audio_queue.qsize(),
            'use_whisper': self.use_whisper,
            'use_porcupine': self.use_porcupine,
            'last_interaction': self.last_interaction_time
        }
    
    def set_tts_voice(self, voice_name):
        """è®¾ç½®TTSè¯­éŸ³"""
        available_voices = [
            "zh-CN-XiaoxiaoNeural",  # å¥³å£°
            "zh-CN-YunxiNeural",     # ç”·å£°
            "zh-CN-YunyangNeural",   # ç”·å£°
            "zh-CN-XiaoyiNeural",    # å¥³å£°
            "zh-CN-YunjianNeural"    # ç”·å£°
        ]
        
        if voice_name in available_voices:
            self.tts_voice = voice_name
            logger.info(f"TTSè¯­éŸ³è®¾ç½®ä¸º: {voice_name}")
        else:
            logger.warning(f"ä¸æ”¯æŒçš„è¯­éŸ³: {voice_name}ï¼Œå¯ç”¨è¯­éŸ³: {available_voices}")
    
    def set_tts_parameters(self, rate=None, volume=None):
        """è®¾ç½®TTSå‚æ•°"""
        if rate is not None:
            self.tts_rate = rate
            logger.info(f"TTSè¯­é€Ÿè®¾ç½®ä¸º: {rate}")
        
        if volume is not None:
            self.tts_volume = volume
            logger.info(f"TTSéŸ³é‡è®¾ç½®ä¸º: {volume}")
    
    def clear_queues(self):
        """æ¸…ç©ºæ‰€æœ‰é˜Ÿåˆ—"""
        while not self.audio_queue.empty():
            try:
                self.audio_queue.get_nowait()
            except queue.Empty:
                break
                
        while not self.tts_queue.empty():
            try:
                self.tts_queue.get_nowait()
            except queue.Empty:
                break
        
        logger.info("éŸ³é¢‘å’ŒTTSé˜Ÿåˆ—å·²æ¸…ç©º")
    
    def force_wake_up(self):
        """å¼ºåˆ¶å”¤é†’ï¼ˆç”¨äºŽæµ‹è¯•æˆ–æ‰‹åŠ¨æ¿€æ´»ï¼‰"""
        if self.conversation_mode:
            self.wake_word_detected = True
            self.last_interaction_time = time.time()
            self.speak_text("æˆ‘è¢«å”¤é†’äº†ï¼Œè¯·è¯´~", priority=True)
            
            if self.expression_controller:
                self.expression_controller.show_listening_animation()
            
            logger.info("å¼ºåˆ¶å”¤é†’æˆåŠŸ")
            return True
        else:
            logger.warning("å¯¹è¯æ¨¡å¼æœªå¯åŠ¨ï¼Œæ— æ³•å¼ºåˆ¶å”¤é†’")
            return False
    
    def get_available_voices(self):
        """èŽ·å–å¯ç”¨çš„TTSè¯­éŸ³åˆ—è¡¨"""
        return [
            {"name": "zh-CN-XiaoxiaoNeural", "description": "æ™“æ™“ - å¥³å£°"},
            {"name": "zh-CN-YunxiNeural", "description": "äº‘å¸Œ - ç”·å£°"},
            {"name": "zh-CN-YunyangNeural", "description": "äº‘æ‰¬ - ç”·å£°"},
            {"name": "zh-CN-XiaoyiNeural", "description": "æ™“ä¼Š - å¥³å£°"},
            {"name": "zh-CN-YunjianNeural", "description": "äº‘å¥ - ç”·å£°"}
        ]

# æµ‹è¯•å’Œæ¼”ç¤ºå‡½æ•°
def test_enhanced_voice_control():
    """æµ‹è¯•å¢žå¼ºè¯­éŸ³æŽ§åˆ¶åŠŸèƒ½"""
    print("=== å¢žå¼ºè¯­éŸ³æŽ§åˆ¶å™¨æµ‹è¯• ===")
    
    # åˆ›å»ºå¢žå¼ºè¯­éŸ³æŽ§åˆ¶å™¨
    enhanced_voice = EnhancedVoiceController()
    
    try:
        # æ˜¾ç¤ºç³»ç»ŸçŠ¶æ€
        status = enhanced_voice.get_conversation_status()
        print(f"ç³»ç»ŸçŠ¶æ€: {json.dumps(status, indent=2, ensure_ascii=False)}")
        
        # æ˜¾ç¤ºå¯ç”¨è¯­éŸ³
        voices = enhanced_voice.get_available_voices()
        print("\nå¯ç”¨è¯­éŸ³:")
        for voice in voices:
            print(f"  - {voice['name']}: {voice['description']}")
        
        # å¯åŠ¨å¯¹è¯æ¨¡å¼
        if enhanced_voice.start_conversation_mode():
            print("\nå¯¹è¯æ¨¡å¼å¯åŠ¨æˆåŠŸ")
            print("åŠŸèƒ½è¯´æ˜Ž:")
            print("- è¯´'å¿«å¿«'æ¥å”¤é†’æœºå™¨äºº")
            print("- å”¤é†’åŽå¯ä»¥è¿›è¡Œè‡ªç„¶å¯¹è¯")
            print("- è¯´'å†è§'æ¥ç»“æŸå¯¹è¯")
            print("- 30ç§’æ— äº¤äº’ä¼šè‡ªåŠ¨è¿”å›žå¾…æœº")
            print("- æŒ‰Ctrl+Cé€€å‡ºæµ‹è¯•")
            
            # å¯åŠ¨ç›‘å¬
            listen_thread = threading.Thread(target=enhanced_voice.listen_continuously, daemon=True)
            listen_thread.start()
            
            # ä¿æŒç¨‹åºè¿è¡Œ
            while True:
                time.sleep(1)
                
        else:
            print("å¯¹è¯æ¨¡å¼å¯åŠ¨å¤±è´¥")
            
    except KeyboardInterrupt:
        print("\næ­£åœ¨åœæ­¢...")
        enhanced_voice.stop()
        enhanced_voice.stop_conversation_mode()
        print("æµ‹è¯•ç»“æŸ")

def demo_tts_voices():
    """æ¼”ç¤ºä¸åŒTTSè¯­éŸ³"""
    print("=== TTSè¯­éŸ³æ¼”ç¤º ===")
    
    enhanced_voice = EnhancedVoiceController()
    
    # å¯åŠ¨TTSçº¿ç¨‹
    enhanced_voice.conversation_mode = True
    enhanced_voice.tts_thread = threading.Thread(target=enhanced_voice._tts_worker, daemon=True)
    enhanced_voice.tts_thread.start()
    
    voices = enhanced_voice.get_available_voices()
    test_text = "ä½ å¥½ï¼Œæˆ‘æ˜¯å¿«å¿«ï¼Œå¾ˆé«˜å…´è®¤è¯†ä½ ï¼"
    
    for voice in voices:
        print(f"\næµ‹è¯•è¯­éŸ³: {voice['description']}")
        enhanced_voice.set_tts_voice(voice['name'])
        enhanced_voice.speak_text(test_text)
        time.sleep(3)  # ç­‰å¾…æ’­æ”¾å®Œæˆ
    
    enhanced_voice.conversation_mode = False
    print("\nè¯­éŸ³æ¼”ç¤ºå®Œæˆ")

if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1 and sys.argv[1] == "demo":
        demo_tts_voices()
    else:
        test_enhanced_voice_control()
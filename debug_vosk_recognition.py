#!/usr/bin/env python3
"""
è°ƒè¯•Voskä¸­æ–‡è¯†åˆ«é—®é¢˜
ä¸“é—¨ç”¨äºè¯Šæ–­Voskè¯†åˆ«å¤±è´¥çš„åŸå› 
"""

import os
import sys
import time
import speech_recognition as sr
import logging
import json
import numpy as np
import wave
import tempfile

# è®¾ç½®è¯¦ç»†æ—¥å¿—
logging.basicConfig(
    level=logging.DEBUG, 
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

sys.path.insert(0, 'src')

def test_vosk_model_loading():
    """æµ‹è¯•Voskæ¨¡å‹åŠ è½½"""
    print("ğŸ”§ æµ‹è¯•Voskæ¨¡å‹åŠ è½½...")
    
    try:
        import vosk
        print("âœ… Voskåº“å¯¼å…¥æˆåŠŸ")
        
        # è®¾ç½®æ—¥å¿—çº§åˆ«
        vosk.SetLogLevel(0)  # å¯ç”¨è¯¦ç»†æ—¥å¿—
        
        model_path = "models/vosk-model-small-cn-0.22"
        if os.path.exists(model_path):
            print(f"âœ… æ‰¾åˆ°æ¨¡å‹è·¯å¾„: {model_path}")
            
            # å°è¯•åŠ è½½æ¨¡å‹
            model = vosk.Model(model_path)
            print("âœ… Voskæ¨¡å‹åŠ è½½æˆåŠŸ")
            
            # åˆ›å»ºè¯†åˆ«å™¨
            recognizer = vosk.KaldiRecognizer(model, 16000)
            recognizer.SetWords(True)
            print("âœ… Voskè¯†åˆ«å™¨åˆ›å»ºæˆåŠŸ")
            
            return model, recognizer
        else:
            print(f"âŒ æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {model_path}")
            return None, None
            
    except Exception as e:
        print(f"âŒ Voskæµ‹è¯•å¤±è´¥: {e}")
        return None, None

def test_audio_format_conversion():
    """æµ‹è¯•éŸ³é¢‘æ ¼å¼è½¬æ¢"""
    print("\nğŸ”§ æµ‹è¯•éŸ³é¢‘æ ¼å¼è½¬æ¢...")
    
    # åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«
    recognizer = sr.Recognizer()
    microphone = sr.Microphone()
    
    print("ğŸ™ï¸ è¯·è¯´ä¸€å¥ä¸­æ–‡ï¼Œæµ‹è¯•éŸ³é¢‘è½¬æ¢...")
    
    try:
        with microphone as source:
            recognizer.adjust_for_ambient_noise(source, duration=1)
            audio = recognizer.listen(source, timeout=5, phrase_time_limit=5)
        
        # è·å–åŸå§‹éŸ³é¢‘æ•°æ®
        raw_data = audio.get_raw_data()
        sample_rate = audio.sample_rate
        sample_width = audio.sample_width
        
        print(f"ğŸ“Š åŸå§‹éŸ³é¢‘ä¿¡æ¯:")
        print(f"   æ•°æ®é•¿åº¦: {len(raw_data)} å­—èŠ‚")
        print(f"   é‡‡æ ·ç‡: {sample_rate} Hz")
        print(f"   é‡‡æ ·å®½åº¦: {sample_width} å­—èŠ‚")
        print(f"   å£°é“æ•°: 1 (å‡è®¾)")
        
        # è½¬æ¢ä¸ºnumpyæ•°ç»„åˆ†æ
        audio_array = np.frombuffer(raw_data, dtype=np.int16)
        print(f"   æ ·æœ¬æ•°: {len(audio_array)}")
        print(f"   æ—¶é•¿: {len(audio_array) / sample_rate:.2f} ç§’")
        print(f"   æœ€å¤§æŒ¯å¹…: {np.max(np.abs(audio_array))}")
        print(f"   RMSéŸ³é‡: {np.sqrt(np.mean(audio_array**2)):.2f}")
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡é‡‡æ ·
        target_rate = 16000
        if sample_rate != target_rate:
            print(f"ğŸ”„ éœ€è¦é‡é‡‡æ ·: {sample_rate} Hz â†’ {target_rate} Hz")
            
            from scipy import signal
            num_samples = int(len(audio_array) * target_rate / sample_rate)
            resampled_array = signal.resample(audio_array, num_samples)
            resampled_data = resampled_array.astype(np.int16).tobytes()
            
            print(f"   é‡é‡‡æ ·åé•¿åº¦: {len(resampled_data)} å­—èŠ‚")
            print(f"   é‡é‡‡æ ·åæ ·æœ¬æ•°: {len(resampled_array)}")
            
            return resampled_data, target_rate
        else:
            return raw_data, sample_rate
            
    except Exception as e:
        print(f"âŒ éŸ³é¢‘æ ¼å¼è½¬æ¢æµ‹è¯•å¤±è´¥: {e}")
        return None, None

def test_vosk_recognition_step_by_step():
    """é€æ­¥æµ‹è¯•Voskè¯†åˆ«è¿‡ç¨‹"""
    print("\nğŸ”§ é€æ­¥æµ‹è¯•Voskè¯†åˆ«...")
    
    # 1. åŠ è½½æ¨¡å‹
    model, recognizer = test_vosk_model_loading()
    if not model or not recognizer:
        return False
    
    # 2. è·å–éŸ³é¢‘æ•°æ®
    audio_data, sample_rate = test_audio_format_conversion()
    if not audio_data:
        return False
    
    # 3. æµ‹è¯•Voskè¯†åˆ«
    print("\nğŸ¯ å¼€å§‹Voskè¯†åˆ«...")
    
    try:
        # é‡ç½®è¯†åˆ«å™¨
        recognizer.Reset()
        print("âœ… è¯†åˆ«å™¨é‡ç½®æˆåŠŸ")
        
        # åˆ†å—å¤„ç†éŸ³é¢‘æ•°æ®
        chunk_size = 4096
        total_chunks = len(audio_data) // chunk_size
        print(f"ğŸ“¦ éŸ³é¢‘åˆ†ä¸º {total_chunks} ä¸ªå—å¤„ç†")
        
        final_result = None
        partial_results = []
        
        for i in range(0, len(audio_data), chunk_size):
            chunk = audio_data[i:i+chunk_size]
            
            if recognizer.AcceptWaveform(chunk):
                result = recognizer.Result()
                result_dict = json.loads(result)
                print(f"ğŸ“„ å— {i//chunk_size + 1} å®Œæ•´ç»“æœ: {result}")
                
                if result_dict.get('text'):
                    final_result = result_dict['text']
                    break
            else:
                partial = recognizer.PartialResult()
                partial_dict = json.loads(partial)
                if partial_dict.get('partial'):
                    partial_results.append(partial_dict['partial'])
                    print(f"ğŸ”„ å— {i//chunk_size + 1} éƒ¨åˆ†ç»“æœ: {partial_dict['partial']}")
        
        # è·å–æœ€ç»ˆç»“æœ
        if not final_result:
            final_result_json = recognizer.FinalResult()
            final_result_dict = json.loads(final_result_json)
            final_result = final_result_dict.get('text')
            print(f"ğŸ“‹ æœ€ç»ˆç»“æœ: {final_result_json}")
        
        if final_result and final_result.strip():
            print(f"ğŸ‰ Voskè¯†åˆ«æˆåŠŸ: '{final_result}'")
            return True
        elif partial_results:
            print(f"âš ï¸ åªæœ‰éƒ¨åˆ†ç»“æœ: {partial_results}")
            return False
        else:
            print("âŒ Voskæœªè¯†åˆ«åˆ°ä»»ä½•å†…å®¹")
            
            # é¢å¤–è¯Šæ–­
            print("\nğŸ” è¯Šæ–­ä¿¡æ¯:")
            print("å¯èƒ½åŸå› :")
            print("1. éŸ³é¢‘è´¨é‡ä¸å¤Ÿå¥½ï¼ˆå™ªéŸ³å¤ªå¤§ã€éŸ³é‡å¤ªå°ï¼‰")
            print("2. è¯´è¯å†…å®¹ä¸åœ¨æ¨¡å‹è¯æ±‡è¡¨ä¸­")
            print("3. éŸ³é¢‘æ ¼å¼è½¬æ¢æœ‰é—®é¢˜")
            print("4. è¯­é€Ÿè¿‡å¿«æˆ–è¿‡æ…¢")
            print("5. æ–¹è¨€æˆ–å£éŸ³é—®é¢˜")
            
            return False
            
    except Exception as e:
        print(f"âŒ Voskè¯†åˆ«è¿‡ç¨‹å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def save_audio_for_analysis(audio_data, sample_rate, filename="debug_audio.wav"):
    """ä¿å­˜éŸ³é¢‘æ–‡ä»¶ç”¨äºåˆ†æ"""
    try:
        with wave.open(filename, 'wb') as wav_file:
            wav_file.setnchannels(1)  # å•å£°é“
            wav_file.setsampwidth(2)  # 16-bit
            wav_file.setframerate(sample_rate)
            wav_file.writeframes(audio_data)
        
        print(f"ğŸ’¾ éŸ³é¢‘å·²ä¿å­˜: {filename}")
        print(f"   å¯ä»¥ç”¨éŸ³é¢‘æ’­æ”¾å™¨æ£€æŸ¥éŸ³é¢‘è´¨é‡")
        return filename
    except Exception as e:
        print(f"âŒ ä¿å­˜éŸ³é¢‘å¤±è´¥: {e}")
        return None

def test_different_phrases():
    """æµ‹è¯•ä¸åŒçš„ä¸­æ–‡çŸ­è¯­"""
    print("\nğŸ—£ï¸ æµ‹è¯•ä¸åŒä¸­æ–‡çŸ­è¯­çš„è¯†åˆ«æ•ˆæœ...")
    
    test_phrases = [
        "ä½ å¥½",
        "ä»Šå¤©å¤©æ°”å¾ˆå¥½", 
        "æˆ‘æƒ³è¦ä¸€æ¯æ°´",
        "è¯·æ‰“å¼€ç”µè§†",
        "ç°åœ¨å‡ ç‚¹äº†",
        "è°¢è°¢ä½ ",
        "å†è§"
    ]
    
    print("å»ºè®®æµ‹è¯•çš„çŸ­è¯­:")
    for i, phrase in enumerate(test_phrases, 1):
        print(f"  {i}. {phrase}")
    
    model, recognizer = test_vosk_model_loading()
    if not model or not recognizer:
        return
    
    # åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«
    sr_recognizer = sr.Recognizer()
    microphone = sr.Microphone()
    
    success_count = 0
    total_count = 0
    
    for phrase in test_phrases:
        print(f"\n--- æµ‹è¯•çŸ­è¯­: {phrase} ---")
        input(f"å‡†å¤‡è¯´ '{phrase}'ï¼ŒæŒ‰Enterå¼€å§‹å½•éŸ³...")
        
        try:
            with microphone as source:
                sr_recognizer.adjust_for_ambient_noise(source, duration=0.5)
                print("ğŸ™ï¸ æ­£åœ¨å½•éŸ³...")
                audio = sr_recognizer.listen(source, timeout=3, phrase_time_limit=5)
            
            # è½¬æ¢éŸ³é¢‘æ ¼å¼
            raw_data = audio.get_raw_data()
            if audio.sample_rate != 16000:
                from scipy import signal
                audio_array = np.frombuffer(raw_data, dtype=np.int16)
                num_samples = int(len(audio_array) * 16000 / audio.sample_rate)
                resampled_array = signal.resample(audio_array, num_samples)
                audio_data = resampled_array.astype(np.int16).tobytes()
            else:
                audio_data = raw_data
            
            # Voskè¯†åˆ«
            recognizer.Reset()
            if recognizer.AcceptWaveform(audio_data):
                result = json.loads(recognizer.Result())
                text = result.get('text', '').strip()
            else:
                final_result = json.loads(recognizer.FinalResult())
                text = final_result.get('text', '').strip()
            
            total_count += 1
            if text:
                print(f"âœ… è¯†åˆ«ç»“æœ: '{text}'")
                if phrase in text or text in phrase:
                    print("ğŸ¯ è¯†åˆ«æ­£ç¡®ï¼")
                    success_count += 1
                else:
                    print("âš ï¸ è¯†åˆ«ç»“æœä¸é¢„æœŸä¸ç¬¦")
            else:
                print("âŒ æœªè¯†åˆ«åˆ°å†…å®¹")
                
        except Exception as e:
            print(f"âŒ å½•éŸ³æˆ–è¯†åˆ«å¤±è´¥: {e}")
            total_count += 1
    
    print(f"\nğŸ“Š æµ‹è¯•æ€»ç»“:")
    print(f"   æˆåŠŸç‡: {success_count}/{total_count} ({success_count/total_count*100:.1f}%)" if total_count > 0 else "æ— æœ‰æ•ˆæµ‹è¯•")

if __name__ == "__main__":
    print("ğŸ” Voskä¸­æ–‡è¯†åˆ«è°ƒè¯•å·¥å…·")
    print("=" * 60)
    
    # æ£€æŸ¥ä¾èµ–
    try:
        import vosk
        import scipy
        print("âœ… ä¾èµ–åº“æ£€æŸ¥é€šè¿‡")
    except ImportError as e:
        print(f"âŒ ç¼ºå°‘ä¾èµ–åº“: {e}")
        print("è¯·å®‰è£…: pip install vosk scipy")
        sys.exit(1)
    
    # é€æ­¥æµ‹è¯•
    print("\nğŸ§ª å¼€å§‹é€æ­¥æµ‹è¯•...")
    
    # æµ‹è¯•1: å•æ¬¡è¯†åˆ«
    if test_vosk_recognition_step_by_step():
        print("\nğŸ‰ åŸºç¡€è¯†åˆ«æµ‹è¯•é€šè¿‡ï¼")
        
        # æµ‹è¯•2: å¤šçŸ­è¯­æµ‹è¯•
        choice = input("\næ˜¯å¦è¿›è¡Œå¤šçŸ­è¯­æµ‹è¯•ï¼Ÿ(y/n): ").strip().lower()
        if choice == 'y':
            test_different_phrases()
    else:
        print("\nğŸ˜ åŸºç¡€è¯†åˆ«æµ‹è¯•å¤±è´¥")
        print("ğŸ’¡ å»ºè®®:")
        print("1. ç¡®ä¿åœ¨å®‰é™ç¯å¢ƒä¸­æµ‹è¯•")
        print("2. é è¿‘éº¦å…‹é£è¯´è¯")
        print("3. ä½¿ç”¨æ ‡å‡†æ™®é€šè¯å‘éŸ³")
        print("4. è¯­é€Ÿé€‚ä¸­ï¼Œæ¸…æ™°å‘éŸ³")
        print("5. æ£€æŸ¥éº¦å…‹é£éŸ³é‡è®¾ç½®")
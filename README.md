# 机器人控制系统项目总结

## 1. 项目概述

本项目是一个基于树莓派的多功能机器人控制平台。它通过一个集成的Web界面，实现了对机器人的多种控制方式，包括**手动网页控制**、**实时视频监控**以及创新的**中文语音命令控制**。项目架构清晰，功能模块化，易于扩展和维护。

核心功能是提供一个全面的机器人远程操作解决方案，结合了手动精准操控、自主避障行为和便捷的自然语言交互。

---

## 2. 核心功能

- **🤖 多模式运动控制**:
  - 支持前进、后退、左转、右转、左/右平移等全向移动。
  - 支持左前、右前、左后、右后等复合方向移动。

- **🌐 Web控制界面 (`voice_index.html`)**:
  - **实时视频流**: 通过摄像头（PiCamera或USB摄像头）提供机器人第一视角画面。
  - **虚拟摇杆**: 支持在触屏设备上通过虚拟摇杆直观地控制机器人移动。
  - **手动按钮**: 提供九宫格布局的按钮，用于精确控制各个方向的移动。
  - **速度调节**: 可通过滑块实时调整机器人移动速度。
  - **功能开关**: 提供一键切换**自动避障**和**语音控制**功能的开关。

- **🎤 中文语音控制 (`voice_control.py`)**:
  - **离线识别**: 采用 `PocketSphinx` 引擎，无需联网即可在本地进行语音识别。
  - **自然语言命令**: 支持“向前”、“左转”、“快一点”、“停止”等多种中文命令。
  - **高集成度**: 语音控制与Web界面无缝集成，可随时启用或关闭。

- **🛡️ 传感器与自主行为**:
  - **红外传感器**: 用于检测两侧的障碍物。
  - **超声波传感器**: 用于检测前方的障碍物距离。
  - **自动避障**: 结合红外和超声波传感器，实现遇到障碍物时自动后退和转向的避障逻辑。

- **📹 摄像头支持**:
  - 自动检测并兼容树莓派官方 `PiCamera` 和通用的 `USB Webcam`。
  - 在Web界面上提供摄像头开关和重启功能。

---

## 3. 技术实现与架构

### 3.1. 硬件架构

- **主控单元**: 树莓派 (Raspberry Pi)
- **电机驱动**: `PCA9685` I2C PWM驱动板，用于控制多个电机。
- **传感器**: 左右红外避障传感器、`HC-SR04`超声波测距传感器。
- **输入设备**: USB麦克风、摄像头（PiCamera或USB接口）。

### 3.2. 软件架构

- **后端**: 使用 **Python** 和 **Flask** 框架构建Web服务器，处理HTTP请求和WebSocket通信。
- **前端**: 使用 **HTML**, **CSS**, 和 **JavaScript** 构建响应式Web界面。
  - **UI框架**: `Bootstrap` 用于页面布局。
  - **虚拟摇杆**: `NippleJS` 库实现。
- **并发处理**: 使用 **Python的 `threading` 模块** 实现多线程，将Web服务、传感器监控、语音识别等任务在独立的线程中运行，避免相互阻塞。

### 3.3. 关键代码模块

- **`robot_voice_web_control.py`**:
  - **项目主入口**。
  - 使用 `Flask` 创建Web服务，定义了所有API端点（如 `/control`, `/speed`, `/voice_control`）。
  - 集成了 `LOBOROBOT` 硬件控制类和 `VoiceController` 语音控制类。
  - 管理和启动传感器监控、机器人安全监控（超时自动停止）、语音控制等后台线程。

- **`LOBOROBOT.py`**:
  - **硬件抽象层**。
  - 封装了对 `PCA9685` PWM驱动板的底层I2C通信（通过`smbus`库）。
  - 提供了高级的运动控制接口，如 `t_up()` (前进), `turnLeft()` (左转) 等，供上层应用调用。

- **`voice_control.py`**:
  - **独立的语音控制模块**。
  - 使用 `speech_recognition` 库，并配置其使用 `recognize_sphinx()` 进行离线识别。
  - 使用 `pyaudio` 从麦克风捕获音频。
  - 设计了命令队列（`queue`）和处理线程，实现语音识别与命令执行的解耦。

- **`templates/voice_index.html`**:
  - **前端界面**。
  - 通过 `fetch` API 与后端进行异步通信，发送控制命令并获取状态。
  - 实现了虚拟摇杆、所有按钮的事件监听和功能切换的逻辑。

---

## 4. 使用的库与依赖

### 4.1. Python 依赖 (`requirements.txt`)

- `flask`: 轻量级Web服务器框架。
- `RPi.GPIO`: 用于控制树莓派的GPIO引脚，与传感器交互。
- `smbus`: 用于I2C通信，控制PCA9685电机驱动板 (由`LOBOROBOT.py`内部使用)。
- `opencv-python-headless`: 用于处理摄像头图像数据。
- `picamera`: 树莓派官方摄像头库。
- `SpeechRecognition`: 核心语音识别库，支持多种引擎。
- `pyaudio`: 用于跨平台音频I/O。
- `pocketsphinx`: 开源的离线语音识别引擎。

### 4.2. 系统依赖 (`install_voice_dependencies.sh`)

- **音频系统**: `alsa-utils`, `pulseaudio` (提供音频处理基础环境)。
- **编译工具**: `swig`, `pkg-config` (编译`pocketsphinx`等库所需)。
- **开发库**: `libasound2-dev`, `python3-dev` (Python与系统库交互所需)。

---

## 5. 安装与运行

1. **硬件连接**:
   - 连接好电机、传感器、摄像头和USB麦克风。
2. **安装依赖**:
   - 进入 `src` 目录，首先给予安装脚本执行权限，然后运行它来安装所有系统和Python库。
   ```bash
   cd src
   chmod +x install_voice_dependencies.sh
   ./install_voice_dependencies.sh
   ```
3. **启动主程序**:
   - 运行集成了所有功能的Web控制程序。
   ```bash
   python3 robot_voice_web_control.py
   ```
4. **访问与控制**:
   - 在同一局域网的设备（电脑或手机）的浏览器中，访问 `http://<树莓派的IP地址>:5000`。
   - 即可看到控制界面，进行视频监控、手动控制或开启语音控制。

## 6. 未来可扩展方向

- **语音唤醒**: 添加唤醒词功能（如“你好，小车”），避免持续识别。
- **语音反馈**: 机器人通过语音播报回应收到的命令或当前状态。
- **视觉AI功能**:
  - **物体追踪**: 使用OpenCV追踪特定颜色或物体。
  - **人脸识别**: 识别人脸并执行相应动作。
  - **路径规划**: 基于视觉巡线或二维码识别进行路径规划。
- **状态持久化**: 将机器人的设置（如速度）保存，下次启动时自动加载。
